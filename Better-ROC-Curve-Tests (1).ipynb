{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a23fe-daeb-4422-8f0a-0f5403dc8ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in /opt/conda/lib/python3.11/site-packages (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (0.59.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from umap-learn) (4.66.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.4.0)\n",
      "Requirement already satisfied: mplhep in /opt/conda/lib/python3.11/site-packages (0.3.56)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /opt/conda/lib/python3.11/site-packages (from mplhep) (3.8.4)\n",
      "Requirement already satisfied: mplhep-data>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from mplhep) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from mplhep) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from mplhep) (24.0)\n",
      "Requirement already satisfied: uhi>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from mplhep) (0.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->mplhep) (1.16.0)\n",
      "Requirement already satisfied: psycopg2-binary in ./.local/lib/python3.11/site-packages (2.9.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 19:19:56.284505: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: psycopg2-binary\n",
      "Version: 2.9.10\n",
      "Summary: psycopg2 - Python-PostgreSQL Database Adapter\n",
      "Home-page: https://psycopg.org/\n",
      "Author: Federico Di Gregorio\n",
      "Author-email: fog@initd.org\n",
      "License: LGPL with exceptions\n",
      "Location: /home/jovyan/.local/lib/python3.11/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "#Necessary Imports\n",
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
    "#os.system(\"pip freeze > requirements.txt\")\n",
    "#os.system(\"pip install -r requirements.txt\")\n",
    "os.system(\"pip install umap-learn\")\n",
    "os.system(\"pip install mplhep\")\n",
    "os.system(\"pip install psycopg2-binary --user\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import dask.array as da\n",
    "\n",
    "import tensorflow as tf\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "from umap.parametric_umap import ParametricUMAP as PUMAP\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "os.system(\"pip show psycopg2-binary\")\n",
    "sys.path.append(\"/home/jovyan/.local/lib/python3.11/site-packages\")\n",
    "\n",
    "import io\n",
    "import psycopg2\n",
    "import subprocess\n",
    "import pickle\n",
    "# Import necessary libraries\n",
    "from matplotlib.legend import Legend\n",
    "from sklearn.metrics import auc as auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, TensorBoard\n",
    "from keras.layers import Lambda, Concatenate\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e6fc5e-858c-462a-80bd-5716d5d5c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace NaN values with the column median\n",
    "def replace_nan_with_median(data):\n",
    "    \"\"\"Replaces NaN values in each column with the median of the non-NaN values.\"\"\"\n",
    "    for col in range(data.shape[1]):  # Iterate over columns\n",
    "        col_data = data[:, col]\n",
    "        # Compute the median of non-NaN values\n",
    "        non_nan_values = col_data[~np.isnan(col_data)]\n",
    "        if non_nan_values.size > 0:\n",
    "            median_value = np.median(non_nan_values)\n",
    "            # Replace NaN values with the median\n",
    "            col_data[np.isnan(col_data)] = median_value\n",
    "        else:\n",
    "            # If all values are NaN, fill with 0 or a default value\n",
    "            col_data[np.isnan(col_data)] = 0\n",
    "    return data\n",
    "\n",
    "# Function to query in batches and collect data\n",
    "def fetch_data_in_batches(cursor, table_name, id_column, id_list, batch_size=10000):\n",
    "    data = []\n",
    "    for i in range(0, len(id_list), batch_size):\n",
    "        # Extract the current batch of IDs\n",
    "        batch = id_list[i:i + batch_size]\n",
    "        batch_str = ', '.join(map(str, batch))\n",
    "        \n",
    "        # Execute the query for the current batch\n",
    "        query = f\"SELECT * FROM {table_name} WHERE {id_column} IN ({batch_str})\"\n",
    "        print(\"Query: \" + str(i))\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch and extend the data list\n",
    "        data.extend(cursor.fetchall())\n",
    "    return replace_nan_with_median(np.array(data, dtype=float))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def mse_loss(inputs, outputs):\n",
    "    #Mean distance squared between input and output tensors\n",
    "    return tf.math.reduce_mean((inputs - outputs) ** 2, axis=-1)\n",
    "\n",
    "# def make_mse_per_sample(inputs, outputs):\n",
    "#     outputs = tf.cast(outputs, dtype=inputs.dtype)  # make same type\n",
    "\n",
    "#     inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "#     outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "#     # extract pt\n",
    "#     outputs_pt = outputs[:, :, 0]\n",
    "\n",
    "#     # trick with phi (rescaled tanh activation function)\n",
    "#     outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "#     # trick with eta (rescaled tanh activation function)\n",
    "#     outputs_eta_met = outputs[:, 0:1, 1]\n",
    "#     outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "#         outputs[:, ele_off : ele_off + nele, 1]\n",
    "#     )\n",
    "#     outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "#     outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "#         outputs[:, jet_off : jet_off + njet, 1]\n",
    "#     )\n",
    "#     outputs_eta = tf.concat(\n",
    "#         [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "#     )\n",
    "\n",
    "#     # use both tricks\n",
    "#     outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi], axis=-1)\n",
    "\n",
    "#     # mask zero features\n",
    "#     mask = tf.math.not_equal(inputs, 0)\n",
    "#     mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "#     outputs = mask * outputs\n",
    "\n",
    "#     loss = mse_loss(\n",
    "#         tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "#         tf.reshape(outputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "#     )\n",
    "#     return loss\n",
    "\n",
    "def make_mse_per_sample(inputs, outputs):\n",
    "    outputs = tf.cast(outputs, dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "\n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = outputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = outputs[:, :, 3]\n",
    "\n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = outputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        outputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        outputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "    outputs = mask * outputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (nmet + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(outputs, [-1, (nmet + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def make_mse(inputs, outputs):\n",
    "    loss = make_mse_per_sample(inputs, outputs)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def scale_pt(X, pt_scaler=None):\n",
    "    pt = X[:, 0::nfeat]\n",
    "    if pt_scaler is None:\n",
    "        pt_scaler = StandardScaler()\n",
    "        pt_scaled = pt_scaler.fit_transform(pt)\n",
    "    else:\n",
    "        pt_scaled = pt_scaler.transform(pt)\n",
    "    X_scaled = np.copy(X)\n",
    "    X_scaled[:, 0::nfeat] = np.multiply(pt_scaled, pt != 0)\n",
    "    return X_scaled, pt_scaler\n",
    "\n",
    "def plot_ROC(method, fpr, tpr, tpr_1em5):\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f\"{method}, AUC={auc(fpr, tpr)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr[tpr_1em5]*100:.3f}%\",\n",
    "    )\n",
    "\n",
    "def plot_ROC(method, fpr, tpr, tpr_1em5, n_comp):\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f\"{method}-{n_comp}, AUC={auc(fpr, tpr)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr[tpr_1em5]*100:.3f}%\",\n",
    "    )\n",
    "\n",
    "def get_loss_pumap(X_scaled,inv_transform_data):\n",
    "    #Extract loss from model predictions using make_mse_per_sample function analyzed above\n",
    "    return np.array(make_mse_per_sample(X_scaled, inv_transform_data))\n",
    "\n",
    "def get_loss_pca(X_scaled,inv_transform_data):\n",
    "    #Extract loss from model predictions using make_mse_per_sample function analyzed above\n",
    "    return np.array(make_mse_per_sample(X_scaled, inv_transform_data))\n",
    "\n",
    "def make_mse_per_sample_ae_class(inputs, outputs):\n",
    "    outputs = tf.cast(outputs, dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "\n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = outputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = outputs[:, :, 3]\n",
    "\n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = outputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        outputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        outputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "    outputs = mask * outputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(outputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def make_mse_ae(inputs, outputs):\n",
    "    loss = make_mse_per_sample_ae_class(inputs, outputs)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_loss_ae(X, X_scaled, model):\n",
    "    return np.array(make_mse_per_sample_ae_class(X_scaled, model.predict(X, batch_size=1024)))\n",
    "\n",
    "def make_mse_per_sample_vae_class(inputs, outputs, latent_dimension):\n",
    "    mainOutputs = tf.cast(outputs[:, latent_dimension:-latent_dimension], dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "    meanLatentSpaceVector = outputs[:, :latent_dimension]\n",
    "    logVarVector = outputs[:, -latent_dimension:]\n",
    "    beta = 0.5\n",
    "    klDivCoef = (beta) * -0.5\n",
    "    \n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    mainOutputs = tf.reshape(mainOutputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = mainOutputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = mainOutputs[:, :, 3]\n",
    "    \n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(mainOutputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = mainOutputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(mainOutputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    mainOutputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=mainOutputs.dtype)\n",
    "    mainOutputs = mask * mainOutputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    mse_loss_value = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(mainOutputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    mse_loss_value = tf.math.reduce_mean(mse_loss_value, axis=0)\n",
    "    \n",
    "    kl_divergence = tf.math.multiply(klDivCoef, tf.reduce_sum(1 + logVarVector - tf.square(meanLatentSpaceVector) - tf.exp(logVarVector), axis=-1))\n",
    "    kl_divergence = tf.math.reduce_mean(kl_divergence, axis=0)\n",
    "    kl_divergence = tf.cast(kl_divergence, dtype = mse_loss_value.dtype)\n",
    "\n",
    "    # Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = tf.math.add(tf.math.multiply((1 - beta), mse_loss_value), kl_divergence)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def make_mse_vae(inputs, outputs):\n",
    "    global latent_dimension\n",
    "    loss = make_mse_per_sample_vae_class(inputs, outputs, latent_dimension)\n",
    "\n",
    "    #loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def mod_make_mse_per_sample_vae_class(inputs, outputs, latent_dimension):\n",
    "    mainOutputs = tf.cast(outputs[:, latent_dimension:-latent_dimension], dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "    meanLatentSpaceVector = outputs[:, :latent_dimension]\n",
    "    logVarVector = outputs[:, -latent_dimension:]\n",
    "    beta = 0.5\n",
    "    klDivCoef = (beta) * -0.5\n",
    "    \n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    mainOutputs = tf.reshape(mainOutputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = mainOutputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = mainOutputs[:, :, 3]\n",
    "    \n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(mainOutputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = mainOutputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(mainOutputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    mainOutputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=mainOutputs.dtype)\n",
    "    mainOutputs = mask * mainOutputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    mse_loss_value = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(mainOutputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    #mse_loss_value = tf.math.reduce_mean(mse_loss_value, axis=0)\n",
    "    \n",
    "    kl_divergence = tf.math.multiply(klDivCoef, tf.reduce_sum(1 + logVarVector - tf.square(meanLatentSpaceVector) - tf.exp(logVarVector), axis=-1))\n",
    "    #kl_divergence = tf.math.reduce_mean(kl_divergence, axis=0)\n",
    "    kl_divergence = tf.cast(kl_divergence, dtype = mse_loss_value.dtype)\n",
    "\n",
    "    # Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = tf.math.add(tf.math.multiply((1 - beta), mse_loss_value), kl_divergence)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def get_loss_vae(X, X_scaled, latent_dimension, model):\n",
    "    return np.array(mod_make_mse_per_sample_vae_class(X_scaled, model.predict(X, batch_size=1024), latent_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6c793a-68c5-4c1e-94c2-484c6a2e21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_umap_encoder(input_dim, n_components):\n",
    "#     return tf.keras.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "#         tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(n_components),\n",
    "#     ])\n",
    "\n",
    "# def create_umap_decoder(n_components, output_dim):\n",
    "#     return tf.keras.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=(n_components,)),\n",
    "#         tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(output_dim),\n",
    "#     ])\n",
    "\n",
    "# def PUMAP_ROC(signal_data, n_comp):\n",
    "#     # Define the model\n",
    "#     #, parametric_reconstruction=True, autoencoder_loss=True\n",
    "#     input_dim = X_train_scaled.shape[1]  # Get the input feature dimension\n",
    "#     output_dim = input_dim  # Decoder output should match input dim\n",
    "\n",
    "#     # Define encoder and decoder\n",
    "#     encoder = create_umap_encoder(input_dim, n_comp)\n",
    "#     decoder = create_umap_decoder(n_comp, output_dim)\n",
    "    \n",
    "#     #model = PUMAP(n_components=n_comp, low_memory=True)\n",
    "#     # Define the parametric UMAP model\n",
    "#     model = PUMAP(\n",
    "#         n_components=n_comp,\n",
    "#         encoder=encoder,\n",
    "#         decoder=decoder,\n",
    "#         parametric_reconstruction=True,\n",
    "#         autoencoder_loss=True,\n",
    "#         low_memory=True\n",
    "#     )\n",
    "    \n",
    "#     trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "\n",
    "#     #Check existence of pumap_model_{n_comp}.pkl\n",
    "#     # Save variables to a file\n",
    "#     with open(f\"pumap_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "#         pickle.dump(model, file)\n",
    "\n",
    "#     inv_transform_training_data = model.inverse_transform(trainEmbedding)\n",
    "    \n",
    "#     background_loss = get_loss_pumap(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "    \n",
    "#     plt.figure()\n",
    "    \n",
    "#     signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "#     signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "#     merged_labels = np.concatenate(\n",
    "#         [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "#     )\n",
    "    \n",
    "#     print(\"Starting PUMAP signal embedding: \" + signal_label)\n",
    "    \n",
    "#     inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "#     signal_loss = get_loss_pumap(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "#     merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "#     print(\"Successful PUMAP signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "    \n",
    "#     fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "#     tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "#     # fpr_pumap = fpr\n",
    "#     # tpr_pumap = tpr\n",
    "#     # tpr_1em5_pumap = tpr_1em5\n",
    "#     # auc_pumap = auc\n",
    "#     auc_res = auc(fpr, tpr)\n",
    "    \n",
    "#     return (fpr, tpr, tpr_1em5, auc_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62efb59e-b05c-4e24-889a-fed98a7f86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_umap_encoder(input_dim, n_components):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(n_components),\n",
    "    ])\n",
    "\n",
    "def create_umap_decoder(n_components, output_dim):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(n_components,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(output_dim),\n",
    "    ])\n",
    "\n",
    "def PUMAP_ROC(signal_data, n_comp):\n",
    "    input_dim = X_train_scaled.shape[1]  # Get input feature count\n",
    "    output_dim = input_dim\n",
    "\n",
    "    # Define encoder and decoder with batch normalization\n",
    "    encoder = create_umap_encoder(input_dim, n_comp)\n",
    "    decoder = create_umap_decoder(n_comp, output_dim)\n",
    "\n",
    "    keras_fit_kwargs = {\"callbacks\": [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=10**-2,\n",
    "            patience=10,\n",
    "            verbose=1,\n",
    "        )\n",
    "    ]}\n",
    "\n",
    "    # Define PUMAP model with better optimizer settings\n",
    "    model = PUMAP(\n",
    "        verbose=True,\n",
    "        keras_fit_kwargs = keras_fit_kwargs,\n",
    "        n_components=n_comp,\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        n_epochs=20,\n",
    "        #parametric_reconstruction=True,\n",
    "        autoencoder_loss=True,\n",
    "        low_memory=True#,\n",
    "        #optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)  # Reduced LR\n",
    "    )\n",
    "\n",
    "    # Compile model separately (fixes invalid optimizer issue)\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "    trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "\n",
    "    # Save trained model\n",
    "    with open(f\"pumap_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    # Inverse transform training data\n",
    "    inv_transform_training_data = model.inverse_transform(trainEmbedding)\n",
    "    background_loss = get_loss_pumap(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Prepare and scale signal data\n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate([np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0)\n",
    "\n",
    "    print(\"Starting PUMAP signal embedding: \" + signal_label)\n",
    "\n",
    "    # Transform and inverse transform signal data\n",
    "    inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "    signal_loss = get_loss_pumap(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "\n",
    "    print(\"Successful PUMAP signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "\n",
    "    # Compute ROC metrics\n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    auc_res = auc(fpr, tpr)\n",
    "\n",
    "    return (fpr, tpr, tpr_1em5, auc_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be5361a-c2fc-427e-8922-8f6306fa8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE_ROC(signal_data, n_comp):\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            min_delta=0.0001,\n",
    "            cooldown=2,\n",
    "            min_lr=1e-6,\n",
    "        ),\n",
    "        TerminateOnNaN(),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", verbose=1, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    inputs = Input(shape=(X_train[:, 1:].shape[1],))\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(n_comp, kernel_initializer=HeUniform())(x)\n",
    "    x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    outputs = Dense(X_train[:, 1:].shape[1], kernel_initializer=HeUniform())(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss=make_mse_ae)\n",
    "    model.fit(\n",
    "        X_train[:, 1:],\n",
    "        X_train_scaled[:, 1:],\n",
    "        epochs=30,\n",
    "        batch_size=1024,\n",
    "        validation_data=(X_val[:, 1:], X_val_scaled[:, 1:]),\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    # with open(f\"ae_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "    #     pickle.dump(model, file)\n",
    "    model.save(f\"ae_model_{n_comp}.keras\")\n",
    "    \n",
    "    background_loss = get_loss_ae(X_test[:, 1:], X_test_scaled[:, 1:], model)\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    signal_loss = get_loss_ae(signal_data[:, 1:], signal_data_scaled[:, 1:], model)\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    \n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    \n",
    "    # fpr_ae = fpr\n",
    "    # tpr_ae = tpr\n",
    "    # tpr_1em5_ae = tpr_1em5\n",
    "    # auc_ae = auc\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421c07ad-9ce3-4458-a633-b61f64645bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 0\n",
    "# Custom sampling layer to generate epsilon and compute z\n",
    "def sampling(args):\n",
    "    mean, log_var = args\n",
    "    epsilon = tf.random.normal(tf.shape(mean), mean=0.0, stddev=1.0)\n",
    "    return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "    \n",
    "def VAE_ROC(signal_data, n_comp):    \n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            min_delta=0.0001,\n",
    "            cooldown=2,\n",
    "            min_lr=1e-6,\n",
    "        ),\n",
    "        TerminateOnNaN(),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", verbose=1, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    inputs = Input(shape=(X_train[:, 1:].shape[1],))\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    #Block 1\n",
    "    x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #Block 2\n",
    "    x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #Block 3\n",
    "    x = Dense(n_comp, kernel_initializer=HeUniform())(x)\n",
    "    meanLatentSpaceVector = Dense(n_comp, activation='linear')(x)\n",
    "    logVarVector = Dense(n_comp, activation='linear')(x)\n",
    "    # epsilon = tf.random.normal(tf.shape(meanLatentSpaceVector), mean=0.0, stddev=1.0)\n",
    "    # z = meanLatentSpaceVector + tf.exp(0.5 * logVarVector) * epsilon\n",
    "    z = Lambda(sampling)([meanLatentSpaceVector, logVarVector])\n",
    "    \n",
    "    intermediate = z\n",
    "    \n",
    "    # Block 4\n",
    "    z = Dense(16, kernel_initializer=HeUniform())(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = LeakyReLU(alpha=0.3)(z)\n",
    "    \n",
    "    # Block 5\n",
    "    z = Dense(32, kernel_initializer=HeUniform())(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = LeakyReLU(alpha=0.3)(z)\n",
    "    \n",
    "    # decoderEpsilon = tf.random.normal(tf.shape(meanLatentSpaceVector), mean=0.0, stddev=1.0)\n",
    "    # decoderZ = meanLatentSpaceVector + tf.exp(0.5 * logVarVector) * decoderEpsilon\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(X_train[:, 1:].shape[1], kernel_initializer=HeUniform())(z)\n",
    "    outputs = Concatenate(axis=1)([meanLatentSpaceVector, outputs, logVarVector])\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    global latent_dimension\n",
    "    latent_dimension = n_comp\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss=make_mse_vae)\n",
    "    model.fit(\n",
    "        X_train[:, 1:],\n",
    "        X_train_scaled[:, 1:],\n",
    "        epochs=30,\n",
    "        batch_size=1024,\n",
    "        validation_data=(X_val[:, 1:], X_val_scaled[:, 1:]),\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    # with open(f\"vae_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "    #     pickle.dump(model, file)\n",
    "    model.save(f\"vae_model_{n_comp}.keras\")\n",
    "    \n",
    "    background_loss = get_loss_vae(X_test[:, 1:], X_test_scaled[:, 1:], n_comp, model)\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    signal_loss = get_loss_vae(signal_data[:, 1:], signal_data_scaled[:, 1:], n_comp, model)\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "    # Remove NaN or infinity values from losses\n",
    "    valid_indices = ~np.isnan(merged_loss) & ~np.isinf(merged_loss)\n",
    "    filtered_labels = merged_labels[valid_indices]\n",
    "    filtered_loss = merged_loss[valid_indices]\n",
    "    \n",
    "    #fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    fpr, tpr, thresholds = roc_curve(filtered_labels, filtered_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    \n",
    "    # fpr_vae = fpr\n",
    "    # tpr_vae = tpr\n",
    "    # tpr_1em5_vae = tpr_1em5\n",
    "    # auc_vae = auc\n",
    "\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2dc618-cd05-47a7-b471-9ff3c0b08cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_ROC(signal_data, n_comp):\n",
    "    model = PCA(n_components=n_comp)\n",
    "    \n",
    "    trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    with open(f\"pca_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    \n",
    "    inv_transform_training_data = model.inverse_transform(trainEmbedding)\n",
    "    background_loss = get_loss_pca(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "    \n",
    "    # _ = plt.figure()\n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    \n",
    "    # print(\"Starting PCA signal embedding: \" + signal_label)\n",
    "    inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "    \n",
    "    signal_loss = get_loss_pca(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "    # print(\"Successful PCA signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d4a294-b68d-400f-91c5-d5cf60731497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 0\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(host=\"adc-2021.c7skue2e0u6i.us-east-1.rds.amazonaws.com\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"UM#37tz;80\",\n",
    "                        port=\"5432\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Set the schema to be used\n",
    "cur.execute(\"SET search_path TO l1anomaly\")\n",
    "#WHOLE DATASET LINE\n",
    "#random_background_indices = np.random.choice(13450000, size=13450000, replace=False)\n",
    "# random_background_indices = np.random.choice(13450000, 1000000, replace=False)\n",
    "random_background_indices = np.random.choice(13450000, 25000, replace=False)\n",
    "# random_signal_indices = np.random.choice(600000, size=600000, replace=False)\n",
    "# random_background_indices = np.random.choice(1560000, size=1560000, replace=False)\n",
    "random_signal_indices = np.random.choice(690000, size=17250, replace=False)\n",
    "# random_signal_indices = np.random.choice(690000, size=1000, replace=False)\n",
    "# random_background_indices = np.random.choice(10000, size=10000, replace=False)\n",
    "# random_signal_indices = np.random.choice(10000, size=10000, replace=False)\n",
    "# Convert numpy arrays to comma-separated strings\n",
    "random_background_indices_str = ', '.join(map(str, random_background_indices))\n",
    "random_signal_indices_str = ', '.join(map(str, random_signal_indices))\n",
    "\n",
    "# cur.execute(f\"SELECT * FROM background_for_training WHERE idbackground_for_training IN ({random_background_indices_str})\")\n",
    "# background_data = cur.fetchall()\n",
    "\n",
    "cur.execute(f\"SELECT * FROM hToTauTau_13TeV_PU20_filtered WHERE idhToTauTau_13TeV_PU20_filtered IN ({random_signal_indices_str})\")\n",
    "signal_data = cur.fetchall()\n",
    "\n",
    "# background_data = np.array(background_data, dtype=float)\n",
    "signal_data = np.array(signal_data, dtype=float)\n",
    "\n",
    "# Replace NaN values in background and signal data\n",
    "# background_data = replace_nan_with_median(background_data)\n",
    "signal_data = replace_nan_with_median(signal_data)\n",
    "\n",
    "#Let's try getting the background data in with batching\n",
    "# Fetch background data in batches\n",
    "background_data = fetch_data_in_batches(\n",
    "    cur,\n",
    "    table_name=\"background_for_training\",\n",
    "    id_column=\"idbackground_for_training\",\n",
    "    id_list=random_background_indices,\n",
    "    batch_size=500000  # Adjust batch size as needed\n",
    ")\n",
    "\n",
    "# # Fetch signal data in batches\n",
    "# signal_data = fetch_data_in_batches(\n",
    "#     cur,\n",
    "#     table_name=\"hToTauTau_13TeV_PU20_filtered\",\n",
    "#     id_column=\"idhToTauTau_13TeV_PU20_filtered\",\n",
    "#     id_list=random_signal_indices,\n",
    "#     batch_size=100000\n",
    "# )\n",
    "\n",
    "# Signal label\n",
    "signal_label = \"$h^{{0}} \\\\to \\\\tau\\\\tau$\"\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e535a7-b552-4acc-804a-3b35982bc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamental Constants\n",
    "\n",
    "nfeat = 4\n",
    "nmet = 1\n",
    "nele = 4\n",
    "nmu = 4\n",
    "njet = 10\n",
    "ele_off = 1\n",
    "mu_off = nmet + nele\n",
    "jet_off = nmet + nele + nmu\n",
    "phi_max = np.pi\n",
    "ele_eta_max = 3.0\n",
    "mu_eta_max = 2.1\n",
    "jet_eta_max = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eade1629-1de5-4922-8aa2-1d1c19588583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start with Gaussian\n",
    "# background_data_reduced, extraneous = train_test_split(background_data, test_size = 0.5)\n",
    "\n",
    "\n",
    "X_train_val, X_test = train_test_split(background_data.reshape(background_data.shape[0], -1), test_size=0.2, shuffle=True)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.2, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "merged_data = np.concatenate([X_test, signal_data], axis=0)\n",
    "merged_labels = np.concatenate([np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0)\n",
    "merged_data_trans = scaler.transform(merged_data)\n",
    "merged_loss = np.sum(merged_data_trans ** 2, axis=-1)\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_gaussian = fpr\n",
    "tpr_gaussian = tpr\n",
    "tpr_1em5_gaussian = tpr_1em5\n",
    "auc_gaussian = auc(fpr, tpr)\n",
    "plt.plot(fpr_gaussian, tpr_gaussian, label=f\"Gaussian, AUC={auc(fpr_gaussian, tpr_gaussian)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_gaussian[tpr_1em5_gaussian]*100:.3f}%\")\n",
    "plt.legend(title = str(signal_label) +\" baseline\")\n",
    "plt.plot([1e-6, 1], [1e-6, 1], 'k--')\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], 'r-.')\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72fb2b4d-777b-4203-a41e-6902e13e229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue with PUMAP\n",
    "X_train_scaled, pt_scaler = scale_pt(X_train)\n",
    "\n",
    "X_test_scaled, _ = scale_pt(X_test, pt_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b10665-156a-43e4-8a99-12204e3c285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParametricUMAP(autoencoder_loss=True, decoder=<Sequential name=sequential_1, built=True>, encoder=<Sequential name=sequential, built=True>, keras_fit_kwargs={'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7fa8da2c4d10>]})\n",
      "Mon Feb  3 19:20:31 2025 Construct fuzzy simplicial set\n",
      "Mon Feb  3 19:20:31 2025 Finding Nearest Neighbors\n",
      "Mon Feb  3 19:20:31 2025 Building RP forest with 11 trees\n",
      "Mon Feb  3 19:20:34 2025 NN descent for 14 iterations\n",
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Mon Feb  3 19:20:43 2025 Finished Nearest Neighbor Search\n",
      "Mon Feb  3 19:20:45 2025 Construct embedding\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'umap_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:588: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1940\n",
      "Epoch 2/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1671\n",
      "Epoch 3/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1617\n",
      "Epoch 4/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1592\n",
      "Epoch 5/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1582\n",
      "Epoch 6/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1574\n",
      "Epoch 7/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1573\n",
      "Epoch 8/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1567\n",
      "Epoch 9/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1560\n",
      "Epoch 10/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1560\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step\n",
      "Mon Feb  3 19:20:57 2025 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle encoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle decoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle keras_fit_kwargs: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle parametric_model: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle optimizer: Can't pickle local object 'BaseOptimizer.__init__.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  3 19:20:59 2025 Worst tree score: 0.93200000\n",
      "Mon Feb  3 19:20:59 2025 Mean tree score: 0.93573295\n",
      "Mon Feb  3 19:20:59 2025 Best tree score: 0.94112500\n",
      "Mon Feb  3 19:21:00 2025 Forward diversification reduced edges from 240000 to 85347\n",
      "Mon Feb  3 19:21:02 2025 Reverse diversification reduced edges from 85347 to 85347\n",
      "Mon Feb  3 19:21:04 2025 Degree pruning reduced edges from 83126 to 83126\n",
      "Mon Feb  3 19:21:04 2025 Resorting data and graph based on tree order\n",
      "Mon Feb  3 19:21:04 2025 Building and compiling search function\n",
      "Mon Feb  3 19:21:06 2025 Building and compiling search function\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2246a1eda663451c90b2b82bbe7d7367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/6 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PUMAP signal embedding: $h^{{0}} \\to \\tau\\tau$\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af615b6be0a4fe8bc84c00db7830d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/6 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful PUMAP signal embedding, inverse transform, and loss computations: $h^{{0}} \\to \\tau\\tau$\n",
      "ParametricUMAP(autoencoder_loss=True, decoder=<Sequential name=sequential_3, built=True>, encoder=<Sequential name=sequential_2, built=True>, keras_fit_kwargs={'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7fa8cd90b190>]})\n",
      "Mon Feb  3 19:23:58 2025 Construct fuzzy simplicial set\n",
      "Mon Feb  3 19:23:58 2025 Finding Nearest Neighbors\n",
      "Mon Feb  3 19:23:58 2025 Building RP forest with 11 trees\n",
      "Mon Feb  3 19:23:58 2025 NN descent for 14 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Mon Feb  3 19:23:59 2025 Finished Nearest Neighbor Search\n",
      "Mon Feb  3 19:23:59 2025 Construct embedding\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'umap_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:588: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1905\n",
      "Epoch 2/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1654\n",
      "Epoch 3/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1607\n",
      "Epoch 4/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1582\n",
      "Epoch 5/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1576\n",
      "Epoch 6/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1570\n",
      "Epoch 7/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1562\n",
      "Epoch 8/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1558\n",
      "Epoch 9/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1553\n",
      "Epoch 10/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1550\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step\n",
      "Mon Feb  3 19:24:10 2025 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle encoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle decoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle keras_fit_kwargs: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle parametric_model: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle optimizer: Can't pickle local object 'BaseOptimizer.__init__.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  3 19:24:10 2025 Worst tree score: 0.92968750\n",
      "Mon Feb  3 19:24:10 2025 Mean tree score: 0.93780682\n",
      "Mon Feb  3 19:24:10 2025 Best tree score: 0.94462500\n",
      "Mon Feb  3 19:24:10 2025 Forward diversification reduced edges from 240000 to 85358\n",
      "Mon Feb  3 19:24:10 2025 Reverse diversification reduced edges from 85358 to 85358\n",
      "Mon Feb  3 19:24:10 2025 Degree pruning reduced edges from 83142 to 83142\n",
      "Mon Feb  3 19:24:10 2025 Resorting data and graph based on tree order\n",
      "Mon Feb  3 19:24:11 2025 Building and compiling search function\n",
      "Mon Feb  3 19:24:12 2025 Building and compiling search function\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e2755ec1c14c30b07474587c1d790b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/6 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PUMAP signal embedding: $h^{{0}} \\to \\tau\\tau$\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7b55ee97094375a9ba1bf0ac6cfe16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/6 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful PUMAP signal embedding, inverse transform, and loss computations: $h^{{0}} \\to \\tau\\tau$\n",
      "ParametricUMAP(autoencoder_loss=True, decoder=<Sequential name=sequential_5, built=True>, encoder=<Sequential name=sequential_4, built=True>, keras_fit_kwargs={'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7fa89c2bfb10>]})\n",
      "Mon Feb  3 19:29:02 2025 Construct fuzzy simplicial set\n",
      "Mon Feb  3 19:29:02 2025 Finding Nearest Neighbors\n",
      "Mon Feb  3 19:29:02 2025 Building RP forest with 11 trees\n",
      "Mon Feb  3 19:29:02 2025 NN descent for 14 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Mon Feb  3 19:29:03 2025 Finished Nearest Neighbor Search\n",
      "Mon Feb  3 19:29:03 2025 Construct embedding\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'umap_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:588: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1909\n",
      "Epoch 2/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1640\n",
      "Epoch 3/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1592\n",
      "Epoch 4/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1574\n",
      "Epoch 5/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1566\n",
      "Epoch 6/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1560\n",
      "Epoch 7/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1556\n",
      "Epoch 8/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1559\n",
      "Epoch 9/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1551\n",
      "Epoch 10/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1548\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step\n",
      "Mon Feb  3 19:29:14 2025 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle encoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle decoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle keras_fit_kwargs: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle parametric_model: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle optimizer: Can't pickle local object 'BaseOptimizer.__init__.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  3 19:29:15 2025 Worst tree score: 0.93287500\n",
      "Mon Feb  3 19:29:15 2025 Mean tree score: 0.93752841\n",
      "Mon Feb  3 19:29:15 2025 Best tree score: 0.94312500\n",
      "Mon Feb  3 19:29:15 2025 Forward diversification reduced edges from 240000 to 85351\n",
      "Mon Feb  3 19:29:15 2025 Reverse diversification reduced edges from 85351 to 85351\n",
      "Mon Feb  3 19:29:15 2025 Degree pruning reduced edges from 83134 to 83134\n",
      "Mon Feb  3 19:29:15 2025 Resorting data and graph based on tree order\n",
      "Mon Feb  3 19:29:15 2025 Building and compiling search function\n",
      "Mon Feb  3 19:29:16 2025 Building and compiling search function\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5d799f456947a68772eab041fe5716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/6 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PUMAP signal embedding: $h^{{0}} \\to \\tau\\tau$\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068abdc1e6dc4213b9edce7da723c06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/6 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful PUMAP signal embedding, inverse transform, and loss computations: $h^{{0}} \\to \\tau\\tau$\n",
      "ParametricUMAP(autoencoder_loss=True, decoder=<Sequential name=sequential_7, built=True>, encoder=<Sequential name=sequential_6, built=True>, keras_fit_kwargs={'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7fa8cdd74d10>]})\n",
      "Mon Feb  3 19:43:12 2025 Construct fuzzy simplicial set\n",
      "Mon Feb  3 19:43:12 2025 Finding Nearest Neighbors\n",
      "Mon Feb  3 19:43:12 2025 Building RP forest with 11 trees\n",
      "Mon Feb  3 19:43:12 2025 NN descent for 14 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Mon Feb  3 19:43:13 2025 Finished Nearest Neighbor Search\n",
      "Mon Feb  3 19:43:13 2025 Construct embedding\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'umap_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:588: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1918\n",
      "Epoch 2/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1661\n",
      "Epoch 3/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1605\n",
      "Epoch 4/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1583\n",
      "Epoch 5/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1575\n",
      "Epoch 6/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1567\n",
      "Epoch 7/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1562\n",
      "Epoch 8/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1560\n",
      "Epoch 9/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1555\n",
      "Epoch 10/10\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1557\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step\n",
      "Mon Feb  3 19:43:24 2025 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle encoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle decoder: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle keras_fit_kwargs: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle parametric_model: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n",
      "/opt/conda/lib/python3.11/site-packages/umap/parametric_umap.py:946: UserWarning: Did not pickle optimizer: Can't pickle local object 'BaseOptimizer.__init__.<locals>.<lambda>'\n",
      "  warn(\"Did not pickle {}: {}\".format(key, e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  3 19:43:24 2025 Worst tree score: 0.93100000\n",
      "Mon Feb  3 19:43:24 2025 Mean tree score: 0.93811932\n",
      "Mon Feb  3 19:43:24 2025 Best tree score: 0.94406250\n",
      "Mon Feb  3 19:43:25 2025 Forward diversification reduced edges from 240000 to 85350\n",
      "Mon Feb  3 19:43:25 2025 Reverse diversification reduced edges from 85350 to 85350\n",
      "Mon Feb  3 19:43:25 2025 Degree pruning reduced edges from 83124 to 83124\n",
      "Mon Feb  3 19:43:25 2025 Resorting data and graph based on tree order\n",
      "Mon Feb  3 19:43:25 2025 Building and compiling search function\n",
      "Mon Feb  3 19:43:26 2025 Building and compiling search function\n"
     ]
    }
   ],
   "source": [
    "(fpr_pumap_two, tpr_pumap_two, tpr_1em5_pumap_two, auc_pumap_two) = PUMAP_ROC(signal_data, 2)\n",
    "(fpr_pumap_three, tpr_pumap_three, tpr_1em5_pumap_three, auc_pumap_three) = PUMAP_ROC(signal_data, 3)\n",
    "(fpr_pumap_four, tpr_pumap_four, tpr_1em5_pumap_four, auc_pumap_four) = PUMAP_ROC(signal_data, 4)\n",
    "(fpr_pumap_five, tpr_pumap_five, tpr_1em5_pumap_five, auc_pumap_five) = PUMAP_ROC(signal_data, 5)\n",
    "# (fpr_pumap_eight, tpr_pumap_eight, tpr_1em5_pumap_eight, auc_pumap_eight) = PUMAP_ROC(signal_data, 8)\n",
    "# (fpr_pumap_ten, tpr_pumap_ten, tpr_1em5_pumap_ten, auc_pumap_ten) = PUMAP_ROC(signal_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8bf34-3939-40eb-9448-15982a4ff49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_two, tpr_pumap_two, tpr_1em5_pumap_two, 2)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_three, tpr_pumap_three, tpr_1em5_pumap_three, 3)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_four, tpr_pumap_four, tpr_1em5_pumap_four, 4)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_five, tpr_pumap_five, tpr_1em5_pumap_five, 5)\n",
    "# plot_ROC(\"PUMAP\", fpr_pumap_eight, tpr_pumap_eight, tpr_1em5_pumap_eight, 8)\n",
    "# plot_ROC(\"PUMAP\", fpr_pumap_ten, tpr_pumap_ten, tpr_1em5_pumap_ten, 10)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "pumap_roc_buffer = io.BytesIO()\n",
    "plt.savefig(pumap_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "pumap_roc_buffer.seek(0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0005b5-3560-431b-b245-616c93e606d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best PUMAP targets for the ultimate plot\n",
    "auc_pumap_dict = {}\n",
    "tpr_1em5_pumap_dict = {}\n",
    "\n",
    "for i in range(2, 6):\n",
    "    (fpr_pumap_test, tpr_pumap_test, tpr_1em5_pumap_test, auc_pumap_test) = PUMAP_ROC(signal_data, i)\n",
    "    auc_pumap_dict[i] = auc_pumap_test\n",
    "    tpr_1em5_pumap_dict[i] = tpr_1em5_pumap_test\n",
    "\n",
    "sorted_auc_pumap_dict = dict(sorted(auc_pumap_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_pumap_dict = dict(sorted(tpr_1em5_pumap_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_pumap_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_pumap_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_pumap = max(sorted_auc_pumap_dict, key=sorted_auc_pumap_dict.get)\n",
    "k_prime_pumap = max(sorted_tpr_1em5_pumap_dict, key=sorted_tpr_1em5_pumap_dict.get)\n",
    "\n",
    "print(k_pumap)\n",
    "print(k_prime_pumap)\n",
    "\n",
    "(fpr_pumap_target, tpr_pumap_target, tpr_1em5_pumap_target, auc_pumap_target) = PUMAP_ROC(signal_data, k_pumap)\n",
    "(fpr_pumap_target_two, tpr_pumap_target_two, tpr_1em5_pumap_target_two, auc_pumap_target_two) = PUMAP_ROC(signal_data, k_prime_pumap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa2e0d-5251-4c36-8a66-4e21d8cb910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = PCA(n_components=10)\n",
    "\n",
    "# trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "# inv_transform_training_data = model.inverse_transform(trainEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82335ba-b1dd-40b5-a2f1-f96374eb9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_loss = get_loss_pca(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "# signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "# merged_labels = np.concatenate(\n",
    "#     [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "# )\n",
    "\n",
    "# print(\"Starting PCA signal embedding: \" + signal_label)\n",
    "# inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "\n",
    "# signal_loss = get_loss_pca(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "# merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "\n",
    "# print(\"Successful PCA signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "# tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "# fpr_pca = fpr\n",
    "# tpr_pca = tpr\n",
    "# tpr_1em5_pca = tpr_1em5\n",
    "# auc_pca = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcba64b-ac4d-46dd-9d9b-075b30ddbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled, _ = scale_pt(X_val, pt_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaf381-2678-4251-b9bb-cd706fef9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_ae_two, tpr_ae_two, tpr_1em5_ae_two, auc_ae_two) = AE_ROC(signal_data, 2)\n",
    "(fpr_ae_three, tpr_ae_three, tpr_1em5_ae_three, auc_ae_three) = AE_ROC(signal_data, 3)\n",
    "(fpr_ae_four, tpr_ae_four, tpr_1em5_ae_four, auc_ae_four) = AE_ROC(signal_data, 4)\n",
    "(fpr_ae_five, tpr_ae_five, tpr_1em5_ae_five, auc_ae_five) = AE_ROC(signal_data, 5)\n",
    "# (fpr_ae_eight, tpr_ae_eight, tpr_1em5_ae_eight, auc_ae_eight) = AE_ROC(signal_data, 8)\n",
    "# (fpr_ae_ten, tpr_ae_ten, tpr_1em5_ae_ten, auc_ae_ten) = AE_ROC(signal_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72bdab-88fc-42ef-909b-9e5d9f8df502",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"DNNAE\", fpr_ae_two, tpr_ae_two, tpr_1em5_ae_two, 2)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_three, tpr_ae_three, tpr_1em5_ae_three, 3)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_four, tpr_ae_four, tpr_1em5_ae_four, 4)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_five, tpr_ae_five, tpr_1em5_ae_five, 5)\n",
    "# plot_ROC(\"DNNAE\", fpr_ae_eight, tpr_ae_eight, tpr_1em5_ae_eight, 8)\n",
    "# plot_ROC(\"DNNAE\", fpr_ae_ten, tpr_ae_ten, tpr_1em5_ae_ten, 10)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "ae_roc_buffer = io.BytesIO()\n",
    "plt.savefig(ae_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "ae_roc_buffer.seek(0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ebd1a-8a22-4130-9ee2-9541caf089e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best AE targets for the ultimate plot\n",
    "auc_ae_dict = {}\n",
    "tpr_1em5_ae_dict = {}\n",
    "\n",
    "for i in range(2, 6):\n",
    "    (fpr_ae_test, tpr_ae_test, tpr_1em5_ae_test, auc_ae_test) = AE_ROC(signal_data, i)\n",
    "    auc_ae_dict[i] = auc_ae_test\n",
    "    tpr_1em5_ae_dict[i] = tpr_1em5_ae_test\n",
    "\n",
    "sorted_auc_ae_dict = dict(sorted(auc_ae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_ae_dict = dict(sorted(tpr_1em5_ae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_ae_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_ae_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_ae = max(sorted_auc_ae_dict, key=sorted_auc_ae_dict.get)\n",
    "k_prime_ae = max(sorted_tpr_1em5_ae_dict, key=sorted_tpr_1em5_ae_dict.get)\n",
    "\n",
    "print(k_ae)\n",
    "print(k_prime_ae)\n",
    "\n",
    "(fpr_ae_target, tpr_ae_target, tpr_1em5_ae_target, auc_ae_target) = AE_ROC(signal_data, k_ae)\n",
    "(fpr_ae_target_two, tpr_ae_target_two, tpr_1em5_ae_target_two, auc_ae_target_two) = AE_ROC(signal_data, k_prime_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d0967-c639-496f-add2-a0bcd6ccb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE Stuff starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629640dd-70e5-464a-a2b1-34805f92d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_vae_two, tpr_vae_two, tpr_1em5_vae_two, auc_vae_two) = VAE_ROC(signal_data, 2)\n",
    "(fpr_vae_three, tpr_vae_three, tpr_1em5_vae_three, auc_vae_three) = VAE_ROC(signal_data, 3)\n",
    "(fpr_vae_four, tpr_vae_four, tpr_1em5_vae_four, auc_vae_four) = VAE_ROC(signal_data, 4)\n",
    "(fpr_vae_five, tpr_vae_five, tpr_1em5_vae_five, auc_vae_five) = VAE_ROC(signal_data, 5)\n",
    "# (fpr_vae_eight, tpr_vae_eight, tpr_1em5_vae_eight, auc_vae_eight) = VAE_ROC(signal_data, 8)\n",
    "# (fpr_vae_ten, tpr_vae_ten, tpr_1em5_vae_ten, auc_vae_ten) = VAE_ROC(signal_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a3f03-e17f-4ce2-92b8-9936445eb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_two, tpr_vae_two, tpr_1em5_vae_two, 2)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_three, tpr_vae_three, tpr_1em5_vae_three, 3)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_four, tpr_vae_four, tpr_1em5_vae_four, 4)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_five, tpr_vae_five, tpr_1em5_vae_five, 5)\n",
    "# plot_ROC(\"DNNVAE\", fpr_vae_eight, tpr_vae_eight, tpr_1em5_vae_eight, 8)\n",
    "# plot_ROC(\"DNNVAE\", fpr_vae_ten, tpr_vae_ten, tpr_1em5_vae_ten, 10)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "vae_roc_buffer = io.BytesIO()\n",
    "plt.savefig(vae_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "vae_roc_buffer.seek(0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f50a7-cc2e-43ad-b24e-d60ba4c6a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best VAE targets for the ultimate plot\n",
    "auc_vae_dict = {}\n",
    "tpr_1em5_vae_dict = {}\n",
    "\n",
    "for i in range(2, 6):\n",
    "    (fpr_vae_test, tpr_vae_test, tpr_1em5_vae_test, auc_vae_test) = VAE_ROC(signal_data, i)\n",
    "    auc_vae_dict[i] = auc_vae_test\n",
    "    tpr_1em5_vae_dict[i] = tpr_1em5_vae_test\n",
    "\n",
    "sorted_auc_vae_dict = dict(sorted(auc_vae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_vae_dict = dict(sorted(tpr_1em5_vae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_vae_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_vae_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_vae = max(sorted_auc_vae_dict, key=sorted_auc_vae_dict.get)\n",
    "k_prime_vae = max(sorted_tpr_1em5_vae_dict, key=sorted_tpr_1em5_vae_dict.get)\n",
    "\n",
    "print(k_vae)\n",
    "print(k_prime_vae)\n",
    "\n",
    "(fpr_vae_target, tpr_vae_target, tpr_1em5_vae_target, auc_vae_target) = VAE_ROC(signal_data, k_vae)\n",
    "(fpr_vae_target_two, tpr_vae_target_two, tpr_1em5_vae_target_two, auc_vae_target_two) = VAE_ROC(signal_data, k_prime_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34234e7e-16b7-4704-bbf4-bd4d84886769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check background_loss\n",
    "# print(\"Background Loss: \", np.any(np.isnan(background_loss)), np.any(np.isinf(background_loss)), np.max(background_loss))\n",
    "\n",
    "# # Check signal_loss\n",
    "# print(\"Signal Loss: \", np.any(np.isnan(signal_loss)), np.any(np.isinf(signal_loss)), np.max(signal_loss))\n",
    "\n",
    "# # Check merged_loss\n",
    "# print(\"Merged Loss: \", np.any(np.isnan(merged_loss)), np.any(np.isinf(merged_loss)), np.max(merged_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a76a75-cd3e-4fb0-8110-7b6c2cd49882",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, auc_pca_two) = PCA_ROC(signal_data, 2)\n",
    "(fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, auc_pca_three) = PCA_ROC(signal_data, 3)\n",
    "(fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, auc_pca_four) = PCA_ROC(signal_data, 4)\n",
    "(fpr_pca_five, tpr_pca_five, tpr_1em5_pca_five, auc_pca_five) = PCA_ROC(signal_data, 5)\n",
    "(fpr_pca_eight, tpr_pca_eight, tpr_1em5_pca_eight, auc_pca_eight) = PCA_ROC(signal_data, 8)\n",
    "(fpr_pca_ten, tpr_pca_ten, tpr_1em5_pca_ten, auc_pca_ten) = PCA_ROC(signal_data, 10)\n",
    "(fpr_pca_twelve, tpr_pca_twelve, tpr_1em5_pca_twelve, auc_pca_twelve) = PCA_ROC(signal_data, 12)\n",
    "(fpr_pca_thirteen, tpr_pca_thirteen, tpr_1em5_pca_thirteen, auc_pca_thirteen) = PCA_ROC(signal_data, 13)\n",
    "(fpr_pca_sixteen, tpr_pca_sixteen, tpr_1em5_pca_sixteen, auc_pca_sixteen) = PCA_ROC(signal_data, 16)\n",
    "(fpr_pca_thirtytwo, tpr_pca_thirtytwo, tpr_1em5_pca_thirtytwo, auc_pca_thirtytwo) = PCA_ROC(signal_data, 32)\n",
    "(fpr_pca_sixtyfour, tpr_pca_sixtyfour, tpr_1em5_pca_sixtyfour, auc_pca_sixtyfour) = PCA_ROC(signal_data, 64)\n",
    "(fpr_pca_seventy, tpr_pca_seventy, tpr_1em5_pca_seventy, auc_pca_seventy) = PCA_ROC(signal_data, 70)\n",
    "(fpr_pca_seventysix, tpr_pca_seventysix, tpr_1em5_pca_seventysix, auc_pca_seventysix) = PCA_ROC(signal_data, 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9cd8d-e32d-4d03-9ff3-cfa6c82ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"PCA\", fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, 2)\n",
    "plot_ROC(\"PCA\", fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, 3)\n",
    "plot_ROC(\"PCA\", fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, 4)\n",
    "plot_ROC(\"PCA\", fpr_pca_five, tpr_pca_five, tpr_1em5_pca_five, 5)\n",
    "plot_ROC(\"PCA\", fpr_pca_eight, tpr_pca_eight, tpr_1em5_pca_eight, 8)\n",
    "plot_ROC(\"PCA\", fpr_pca_ten, tpr_pca_ten, tpr_1em5_pca_ten, 10)\n",
    "plot_ROC(\"PCA\", fpr_pca_twelve, tpr_pca_twelve, tpr_1em5_pca_twelve, 12)\n",
    "plot_ROC(\"PCA\", fpr_pca_thirteen, tpr_pca_thirteen, tpr_1em5_pca_thirteen, 13)\n",
    "plot_ROC(\"PCA\", fpr_pca_sixteen, tpr_pca_sixteen, tpr_1em5_pca_sixteen, 16)\n",
    "plot_ROC(\"PCA\", fpr_pca_thirtytwo, tpr_pca_thirtytwo, tpr_1em5_pca_thirtytwo, 32)\n",
    "plot_ROC(\"PCA\", fpr_pca_sixtyfour, tpr_pca_sixtyfour, tpr_1em5_pca_sixtyfour, 64)\n",
    "plot_ROC(\"PCA\", fpr_pca_seventy, tpr_pca_seventy, tpr_1em5_pca_seventy, 70)\n",
    "plot_ROC(\"PCA\", fpr_pca_seventysix, tpr_pca_seventysix, tpr_1em5_pca_seventysix, 76)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "pca_roc_buffer = io.BytesIO()\n",
    "plt.savefig(pca_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "pca_roc_buffer.seek(0)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Save the main plot without the legend\n",
    "# file_head = \"/tmp/\"\n",
    "# pca_roc_file_name = file_head + f\"New-PCA-ROC-Curve-B{random_background_indices.size}-S{random_signal_indices.size}\"\n",
    "# plt.savefig(f\"{pca_roc_file_name}.png\", format='png', dpi=300, bbox_inches='tight')\n",
    "# plt.close()\n",
    "# Save the main plot with buffer\n",
    "\n",
    "# Create a separate figure for the legend\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))  # Adjust the figure size\n",
    "# legend_fig = ax.legend_ = legend  # Use the existing legend\n",
    "# ax.axis(\"off\")  # Turn off axes for the legend figure\n",
    "\n",
    "# # Save the legend as a separate image\n",
    "# legend_file_name = f\"{roc_file_name}_legend.png\"\n",
    "# fig.savefig(legend_file_name, format='png', dpi=300, bbox_inches='tight')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3036e36-073c-4e93-84a5-d8dd87d98ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best PCA targets for the ultimate plot\n",
    "auc_pca_dict = {}\n",
    "tpr_1em5_pca_dict = {}\n",
    "\n",
    "for i in range(2, 77):\n",
    "    (fpr_pca_test, tpr_pca_test, tpr_1em5_pca_test, auc_pca_test) = PCA_ROC(signal_data, i)\n",
    "    auc_pca_dict[i] = auc_pca_test\n",
    "    tpr_1em5_pca_dict[i] = tpr_1em5_pca_test\n",
    "\n",
    "sorted_auc_pca_dict = dict(sorted(auc_pca_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_pca_dict = dict(sorted(tpr_1em5_pca_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_pca_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_pca_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_pca = max(sorted_auc_pca_dict, key=sorted_auc_pca_dict.get)\n",
    "k_prime_pca = max(sorted_tpr_1em5_pca_dict, key=sorted_tpr_1em5_pca_dict.get)\n",
    "\n",
    "print(k_pca)\n",
    "print(k_prime_pca)\n",
    "\n",
    "(fpr_pca_target, tpr_pca_target, tpr_1em5_pca_target, auc_pca_target) = PCA_ROC(signal_data, k_pca)\n",
    "(fpr_pca_target_two, tpr_pca_target_two, tpr_1em5_pca_target_two, auc_pca_target_two) = PCA_ROC(signal_data, k_prime_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ce434-697b-4961-9d70-8bf742cc57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(25, 8))  # Adjust width and height as needed\n",
    "\n",
    "#Gaussian\n",
    "plot_ROC(\"Gaussian\", fpr_gaussian, tpr_gaussian, tpr_1em5_gaussian, 76)\n",
    "\n",
    "#Get PUMAP-2, PUMAP-3, PUMAP-4, PUMAP with max AUC, PUMAP with max TPR@FPR 10^-5\n",
    "\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_two, tpr_pumap_two, tpr_1em5_pumap_two, 2)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_three, tpr_pumap_three, tpr_1em5_pumap_three, 3)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_four, tpr_pumap_four, tpr_1em5_pumap_four, 4)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_target, tpr_pumap_target, tpr_1em5_pumap_target, k_pumap)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_target_two, tpr_pumap_target_two, tpr_1em5_pumap_target_two, k_prime_pumap)\n",
    "\n",
    "#Get AE-2, AE-3, AE-4, AE with max AUC, AE with max TPR@FPR 10^-5\n",
    "\n",
    "plot_ROC(\"AE\", fpr_ae_two, tpr_ae_two, tpr_1em5_ae_two, 2)\n",
    "plot_ROC(\"AE\", fpr_ae_three, tpr_ae_three, tpr_1em5_ae_three, 3)\n",
    "plot_ROC(\"AE\", fpr_ae_four, tpr_ae_four, tpr_1em5_ae_four, 4)\n",
    "plot_ROC(\"AE\", fpr_ae_target, tpr_ae_target, tpr_1em5_ae_target, k_ae)\n",
    "plot_ROC(\"AE\", fpr_ae_target_two, tpr_ae_target_two, tpr_1em5_ae_target_two, k_prime_ae)\n",
    "\n",
    "#Get VAE-2, VAE-3, VAE-4, VAE with max AUC, VAE with max TPR@FPR 10^-5\n",
    "\n",
    "plot_ROC(\"VAE\", fpr_vae_two, tpr_vae_two, tpr_1em5_vae_two, 2)\n",
    "plot_ROC(\"VAE\", fpr_vae_three, tpr_vae_three, tpr_1em5_vae_three, 3)\n",
    "plot_ROC(\"VAE\", fpr_vae_four, tpr_vae_four, tpr_1em5_vae_four, 4)\n",
    "plot_ROC(\"VAE\", fpr_vae_target, tpr_vae_target, tpr_1em5_vae_target, k_vae)\n",
    "plot_ROC(\"VAE\", fpr_vae_target_two, tpr_vae_target_two, tpr_1em5_vae_target_two, k_prime_vae)\n",
    "\n",
    "#Get PCA-2, PCA-3, PCA-4, PCA with max AUC, PCA with max TPR@FPR 10^-5\n",
    "plot_ROC(\"PCA\", fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, 2)\n",
    "plot_ROC(\"PCA\", fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, 3)\n",
    "plot_ROC(\"PCA\", fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, 4)\n",
    "plot_ROC(\"PCA\", fpr_pca_target, tpr_pca_target, tpr_1em5_pca_target, k_pca)\n",
    "plot_ROC(\"PCA\", fpr_pca_target_two, tpr_pca_target_two, tpr_1em5_pca_target_two, k_prime_pca)\n",
    "\n",
    "# plt.legend(title=f\"{signal_label} Baseline\")\n",
    "# plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "# plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "# plt.xlim([1e-6, 1])\n",
    "# plt.ylim([1e-6, 1])\n",
    "# plt.loglog()\n",
    "\n",
    "# # Adjust layout\n",
    "# # plt.tight_layout()\n",
    "# # Add legend to the plot\n",
    "# legend = plt.legend(\n",
    "#     title=f\"{signal_label} Baseline\",\n",
    "#     bbox_to_anchor=(1.05, 1),\n",
    "#     loc=\"upper left\",\n",
    "#     borderaxespad=0.0\n",
    "# )\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "roc_file_name = f\"New-ROC-Curve-B{random_background_indices.size}-S{random_signal_indices.size}\"\n",
    "plt.savefig(f\"{roc_file_name}.png\", format='png', dpi=300)  # High resolution\n",
    "# Save the plot using buffer\n",
    "roc_buffer = io.BytesIO()\n",
    "plt.savefig(roc_buffer, format='png', dpi=300)  # High resolution\n",
    "roc_buffer.seek(0)\n",
    "plt.close()  # Close the figure to release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdafbc5-4bee-4b41-859a-028ba212b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "# from pathlib import Path\n",
    "\n",
    "# Email details\n",
    "sender_email = \"rosachdeva@ucsd.edu\"\n",
    "#receiver_email = \"rosachdeva@ucsd.edu\"\n",
    "receiver_emails = [\"rosachdeva@ucsd.edu\", \"mquinnan@ucsd.edu\"]  # List of recipients\n",
    "password = \"uuvo esud bmib fvvk\"  # Use app-specific password if using Gmail\n",
    "\n",
    "# Create the email message\n",
    "msg = EmailMessage()\n",
    "msg['Subject'] = 'Final ROC Curve Results'\n",
    "msg['From'] = sender_email\n",
    "#msg['To'] = receiver_email\n",
    "msg['To'] = \", \".join(receiver_emails)  # Join multiple emails into a string\n",
    "\n",
    "\n",
    "# Attach text content\n",
    "msg.set_content(\"Please find the final ROC curves attached.\")\n",
    "\n",
    "# Add the ROC curve image\n",
    "msg.add_attachment(roc_buffer.read(), maintype='image', subtype='png', filename=f\"{roc_file_name}.png\")\n",
    "msg.add_attachment(pumap_roc_buffer.read(), maintype='image', subtype='png', filename=\"pumap_roc_curve.png\")\n",
    "msg.add_attachment(ae_roc_buffer.read(), maintype='image', subtype='png', filename=\"ae_roc_curve.png\")\n",
    "msg.add_attachment(vae_roc_buffer.read(), maintype='image', subtype='png', filename=\"vae_roc_curve.png\")\n",
    "msg.add_attachment(pca_roc_buffer.read(), maintype='image', subtype='png', filename=\"pca_roc_curve.png\")\n",
    "# roc_curve_path = file_head + roc_file_name + \".png\"  # Path to the ROC curve image\n",
    "# pca_roc_curve_path = file_head + pca_roc_file_name + \".png\"  # Path to the PCA ROC curve image\n",
    "# if Path(roc_curve_path).exists():\n",
    "#    with open(roc_curve_path, 'rb') as img:\n",
    "#        img_data = img.read()\n",
    "#        msg.add_attachment(img_data, maintype='image', subtype='png', filename=\"roc_curve.png\")\n",
    "# else:\n",
    "#    print(f\"Error: {roc_curve_path} not found. Ensure the ROC curve image is saved.\")\n",
    "\n",
    "# if Path(pca_roc_curve_path).exists():\n",
    "#    with open(pca_roc_curve_path, 'rb') as img:\n",
    "#        img_data = img.read()\n",
    "#        msg.add_attachment(img_data, maintype='image', subtype='png', filename=\"pca_roc_curve.png\")\n",
    "# else:\n",
    "#    print(f\"Error: {roc_curve_path} not found. Ensure the ROC curve image is saved.\")\n",
    "\n",
    "\n",
    "\n",
    "# Send the email\n",
    "try:\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:  # For Gmail. Use other SMTP servers if needed.\n",
    "        server.login(sender_email, password)\n",
    "        server.send_message(msg)\n",
    "    print(\"Email sent successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error sending email: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15fe26-afcb-40c3-94ea-0761b786d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for Gaussian ROC Curve\n",
    "gaussian_roc_variables = {\n",
    "    'fpr_gaussian': fpr_gaussian,\n",
    "    'tpr_gaussian': tpr_gaussian,\n",
    "    'tpr_1em5_gaussian': tpr_1em5_gaussian,\n",
    "    'auc_gaussian': auc_gaussian\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "gaussian_roc_file = \"gaussian_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(gaussian_roc_file, 'wb') as file:\n",
    "    pickle.dump(gaussian_roc_variables, file)\n",
    "\n",
    "print(f\"Gaussian ROC variables saved to {gaussian_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0521554-e0f0-4703-b030-7a282433d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for PUMAP ROC curve\n",
    "pumap_roc_variables = {\n",
    "    'fpr_pumap_two': fpr_pumap_two,\n",
    "    'tpr_pumap_two': tpr_pumap_two,\n",
    "    'tpr_1em5_pumap_two': tpr_1em5_pumap_two,\n",
    "    'auc_pumap_two': auc_pumap_two,\n",
    "    'fpr_pumap_three': fpr_pumap_three,\n",
    "    'tpr_pumap_three': tpr_pumap_three,\n",
    "    'tpr_1em5_pumap_three': tpr_1em5_pumap_three,\n",
    "    'auc_pumap_three': auc_pumap_three,\n",
    "    'fpr_pumap_four': fpr_pumap_four,\n",
    "    'tpr_pumap_four': tpr_pumap_four,\n",
    "    'tpr_1em5_pumap_four': tpr_1em5_pumap_four,\n",
    "    'auc_pumap_four': auc_pumap_four,\n",
    "    'fpr_pumap_five': fpr_pumap_five,\n",
    "    'tpr_pumap_five': tpr_pumap_five,\n",
    "    'tpr_1em5_pumap_five': tpr_1em5_pumap_five,\n",
    "    'auc_pumap_five': auc_pumap_five,\n",
    "    # 'fpr_pumap_eight': fpr_pumap_eight,\n",
    "    # 'tpr_pumap_eight': tpr_pumap_eight,\n",
    "    # 'tpr_1em5_pumap_eight': tpr_1em5_pumap_eight,\n",
    "    # 'auc_pumap_eight': auc_pumap_eight,\n",
    "    # 'fpr_pumap_ten': fpr_pumap_ten,\n",
    "    # 'tpr_pumap_ten': tpr_pumap_ten,\n",
    "    # 'tpr_1em5_pumap_ten': tpr_1em5_pumap_ten,\n",
    "    # 'auc_pumap_ten': auc_pumap_ten,\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "pumap_roc_file = \"pumap_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(pumap_roc_file, 'wb') as file:\n",
    "    pickle.dump(pumap_roc_variables, file)\n",
    "\n",
    "print(f\"PUMAP ROC variables saved to {pumap_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ca723-5fd1-426e-9312-a04f879e1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for DNNAE ROC curve\n",
    "ae_roc_variables = {\n",
    "    'fpr_ae_two': fpr_ae_two,\n",
    "    'tpr_ae_two': tpr_ae_two,\n",
    "    'tpr_1em5_ae_two': tpr_1em5_ae_two,\n",
    "    'auc_ae_two': auc_ae_two,\n",
    "    'fpr_ae_three': fpr_ae_three,\n",
    "    'tpr_ae_three': tpr_ae_three,\n",
    "    'tpr_1em5_ae_three': tpr_1em5_ae_three,\n",
    "    'auc_ae_three': auc_ae_three,\n",
    "    'fpr_ae_four': fpr_ae_four,\n",
    "    'tpr_ae_four': tpr_ae_four,\n",
    "    'tpr_1em5_ae_four': tpr_1em5_ae_four,\n",
    "    'auc_ae_four': auc_ae_four,\n",
    "    'fpr_ae_five': fpr_ae_five,\n",
    "    'tpr_ae_five': tpr_ae_five,\n",
    "    'tpr_1em5_ae_five': tpr_1em5_ae_five,\n",
    "    'auc_ae_five': auc_ae_five,\n",
    "    # 'fpr_ae_eight': fpr_ae_eight,\n",
    "    # 'tpr_ae_eight': tpr_ae_eight,\n",
    "    # 'tpr_1em5_ae_eight': tpr_1em5_ae_eight,\n",
    "    # 'auc_ae_eight': auc_ae_eight,\n",
    "    # 'fpr_ae_ten': fpr_ae_ten,\n",
    "    # 'tpr_ae_ten': tpr_ae_ten,\n",
    "    # 'tpr_1em5_ae_ten': tpr_1em5_ae_ten,\n",
    "    # 'auc_ae_ten': auc_ae_ten,\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "ae_roc_file = \"ae_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(ae_roc_file, 'wb') as file:\n",
    "    pickle.dump(ae_roc_variables, file)\n",
    "\n",
    "print(f\"DNNAE ROC variables saved to {ae_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdc771-db7d-4fef-b83b-37857771ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for DNNVAE ROC curve\n",
    "vae_roc_variables = {\n",
    "    'fpr_vae_two': fpr_vae_two,\n",
    "    'tpr_vae_two': tpr_vae_two,\n",
    "    'tpr_1em5_vae_two': tpr_1em5_vae_two,\n",
    "    'auc_vae_two': auc_vae_two,\n",
    "    'fpr_vae_three': fpr_vae_three,\n",
    "    'tpr_vae_three': tpr_vae_three,\n",
    "    'tpr_1em5_vae_three': tpr_1em5_vae_three,\n",
    "    'auc_vae_three': auc_vae_three,\n",
    "    'fpr_vae_four': fpr_vae_four,\n",
    "    'tpr_vae_four': tpr_vae_four,\n",
    "    'tpr_1em5_vae_four': tpr_1em5_vae_four,\n",
    "    'auc_vae_four': auc_vae_four,\n",
    "    'fpr_vae_five': fpr_vae_five,\n",
    "    'tpr_vae_five': tpr_vae_five,\n",
    "    'tpr_1em5_vae_five': tpr_1em5_vae_five,\n",
    "    'auc_vae_five': auc_vae_five,\n",
    "    # 'fpr_vae_eight': fpr_vae_eight,\n",
    "    # 'tpr_vae_eight': tpr_vae_eight,\n",
    "    # 'tpr_1em5_vae_eight': tpr_1em5_vae_eight,\n",
    "    # 'auc_vae_eight': auc_vae_eight,\n",
    "    # 'fpr_vae_ten': fpr_vae_ten,\n",
    "    # 'tpr_vae_ten': tpr_vae_ten,\n",
    "    # 'tpr_1em5_vae_ten': tpr_1em5_vae_ten,\n",
    "    # 'auc_vae_ten': auc_vae_ten,\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "vae_roc_file = \"vae_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(vae_roc_file, 'wb') as file:\n",
    "    pickle.dump(vae_roc_variables, file)\n",
    "\n",
    "print(f\"DNNVAE ROC variables saved to {vae_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c13bc6-3fad-484a-b509-342e96efea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for PCA ROC curve\n",
    "pca_roc_variables = {\n",
    "    'fpr_pca_two': fpr_pca_two,\n",
    "    'tpr_pca_two': tpr_pca_two,\n",
    "    'tpr_1em5_pca_two': tpr_1em5_pca_two,\n",
    "    'auc_pca_two': auc_pca_two,\n",
    "    'fpr_pca_three': fpr_pca_three,\n",
    "    'tpr_pca_three': tpr_pca_three,\n",
    "    'tpr_1em5_pca_three': tpr_1em5_pca_three,\n",
    "    'auc_pca_three': auc_pca_three,\n",
    "    'fpr_pca_four': fpr_pca_four,\n",
    "    'tpr_pca_four': tpr_pca_four,\n",
    "    'tpr_1em5_pca_four': tpr_1em5_pca_four,\n",
    "    'auc_pca_four': auc_pca_four,\n",
    "    'fpr_pca_five': fpr_pca_five,\n",
    "    'tpr_pca_five': tpr_pca_five,\n",
    "    'tpr_1em5_pca_five': tpr_1em5_pca_five,\n",
    "    'auc_pca_five': auc_pca_five,\n",
    "    'fpr_pca_eight': fpr_pca_eight,\n",
    "    'tpr_pca_eight': tpr_pca_eight,\n",
    "    'tpr_1em5_pca_eight': tpr_1em5_pca_eight,\n",
    "    'auc_pca_eight': auc_pca_eight,\n",
    "    'fpr_pca_ten': fpr_pca_ten,\n",
    "    'tpr_pca_ten': tpr_pca_ten,\n",
    "    'tpr_1em5_pca_ten': tpr_1em5_pca_ten,\n",
    "    'auc_pca_ten': auc_pca_ten,\n",
    "    'fpr_pca_twelve': fpr_pca_twelve,\n",
    "    'tpr_pca_twelve': tpr_pca_twelve,\n",
    "    'tpr_1em5_pca_twelve': tpr_1em5_pca_twelve,\n",
    "    'auc_pca_twelve': auc_pca_twelve,\n",
    "    'fpr_pca_thirteen': fpr_pca_thirteen,\n",
    "    'tpr_pca_thirteen': tpr_pca_thirteen,\n",
    "    'tpr_1em5_pca_thirteen': tpr_1em5_pca_thirteen,\n",
    "    'auc_pca_thirteen': auc_pca_thirteen,\n",
    "    'fpr_pca_sixteen': fpr_pca_sixteen,\n",
    "    'tpr_pca_sixteen': tpr_pca_sixteen,\n",
    "    'tpr_1em5_pca_sixteen': tpr_1em5_pca_sixteen,\n",
    "    'auc_pca_sixteen': auc_pca_sixteen,\n",
    "    'fpr_pca_thirtytwo': fpr_pca_thirtytwo,\n",
    "    'tpr_pca_thirtytwo': tpr_pca_thirtytwo,\n",
    "    'tpr_1em5_pca_thirtytwo': tpr_1em5_pca_thirtytwo,\n",
    "    'auc_pca_thirtytwo': auc_pca_thirtytwo,\n",
    "    'fpr_pca_sixtyfour': fpr_pca_sixtyfour,\n",
    "    'tpr_pca_sixtyfour': tpr_pca_sixtyfour,\n",
    "    'tpr_1em5_pca_sixtyfour': tpr_1em5_pca_sixtyfour,\n",
    "    'auc_pca_sixtyfour': auc_pca_sixtyfour,\n",
    "    'fpr_pca_seventy': fpr_pca_seventy,\n",
    "    'tpr_pca_seventy': tpr_pca_seventy,\n",
    "    'tpr_1em5_pca_seventy': tpr_1em5_pca_seventy,\n",
    "    'auc_pca_seventy': auc_pca_seventy,\n",
    "    'fpr_pca_seventysix': fpr_pca_seventysix,\n",
    "    'tpr_pca_seventysix': tpr_pca_seventysix,\n",
    "    'tpr_1em5_pca_seventysix': tpr_1em5_pca_seventysix,\n",
    "    'auc_pca_seventysix': auc_pca_seventysix\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "pca_roc_file = \"pca_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(pca_roc_file, 'wb') as file:\n",
    "    pickle.dump(pca_roc_variables, file)\n",
    "\n",
    "print(f\"PCA ROC variables saved to {pca_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ce787-e414-4025-9a3c-19b9cd713a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for the standard ROC curve\n",
    "roc_variables = {\n",
    "    'fpr_gaussian': fpr_gaussian,\n",
    "    'tpr_gaussian': tpr_gaussian,\n",
    "    'tpr_1em5_gaussian': tpr_1em5_gaussian,\n",
    "    'auc_gaussian': auc_gaussian,\n",
    "    'fpr_pumap_two': fpr_pumap_two,\n",
    "    'tpr_pumap_two': tpr_pumap_two,\n",
    "    'tpr_1em5_pumap_two': tpr_1em5_pumap_two,\n",
    "    'auc_pumap_two': auc_pumap_two,\n",
    "    'fpr_pumap_three': fpr_pumap_three,\n",
    "    'tpr_pumap_three': tpr_pumap_three,\n",
    "    'tpr_1em5_pumap_three': tpr_1em5_pumap_three,\n",
    "    'auc_pumap_three': auc_pumap_three,\n",
    "    'fpr_pumap_four': fpr_pumap_four,\n",
    "    'tpr_pumap_four': tpr_pumap_four,\n",
    "    'tpr_1em5_pumap_four': tpr_1em5_pumap_four,\n",
    "    'auc_pumap_four': auc_pumap_four,\n",
    "    'fpr_pumap_target': fpr_pumap_target,\n",
    "    'tpr_pumap_target': tpr_pumap_target,\n",
    "    'tpr_1em5_pumap_target': tpr_1em5_pumap_target,\n",
    "    'auc_pumap_target': auc_pumap_target,\n",
    "    'k_pumap': k_pumap,\n",
    "    'fpr_pumap_target_two': fpr_pumap_target_two,\n",
    "    'tpr_pumap_target_two': tpr_pumap_target_two,\n",
    "    'tpr_1em5_pumap_target_two': tpr_1em5_pumap_target_two,\n",
    "    'auc_pumap_target_two': auc_pumap_target_two,\n",
    "    'k_prime_pumap': k_prime_pumap,\n",
    "    'fpr_ae_two': fpr_ae_two,\n",
    "    'tpr_ae_two': tpr_ae_two,\n",
    "    'tpr_1em5_ae_two': tpr_1em5_ae_two,\n",
    "    'auc_ae_two': auc_ae_two,\n",
    "    'fpr_ae_three': fpr_ae_three,\n",
    "    'tpr_ae_three': tpr_ae_three,\n",
    "    'tpr_1em5_ae_three': tpr_1em5_ae_three,\n",
    "    'auc_ae_three': auc_ae_three,\n",
    "    'fpr_ae_four': fpr_ae_four,\n",
    "    'tpr_ae_four': tpr_ae_four,\n",
    "    'tpr_1em5_ae_four': tpr_1em5_ae_four,\n",
    "    'auc_ae_four': auc_ae_four,\n",
    "    'fpr_ae_target': fpr_ae_target,\n",
    "    'tpr_ae_target': tpr_ae_target,\n",
    "    'tpr_1em5_ae_target': tpr_1em5_ae_target,\n",
    "    'auc_ae_target': auc_ae_target,\n",
    "    'k_ae': k_ae,\n",
    "    'fpr_ae_target_two': fpr_ae_target_two,\n",
    "    'tpr_ae_target_two': tpr_ae_target_two,\n",
    "    'tpr_1em5_ae_target_two': tpr_1em5_ae_target_two,\n",
    "    'auc_ae_target_two': auc_ae_target_two,\n",
    "    'k_prime_ae': k_prime_ae,\n",
    "    'fpr_vae_two': fpr_vae_two,\n",
    "    'tpr_vae_two': tpr_vae_two,\n",
    "    'tpr_1em5_vae_two': tpr_1em5_vae_two,\n",
    "    'auc_vae_two': auc_vae_two,\n",
    "    'fpr_vae_three': fpr_vae_three,\n",
    "    'tpr_vae_three': tpr_vae_three,\n",
    "    'tpr_1em5_vae_three': tpr_1em5_vae_three,\n",
    "    'auc_vae_three': auc_vae_three,\n",
    "    'fpr_vae_four': fpr_vae_four,\n",
    "    'tpr_vae_four': tpr_vae_four,\n",
    "    'tpr_1em5_vae_four': tpr_1em5_vae_four,\n",
    "    'auc_vae_four': auc_vae_four,\n",
    "    'fpr_vae_target': fpr_vae_target,\n",
    "    'tpr_vae_target': tpr_vae_target,\n",
    "    'tpr_1em5_vae_target': tpr_1em5_vae_target,\n",
    "    'auc_vae_target': auc_vae_target,\n",
    "    'k_vae': k_vae,\n",
    "    'fpr_vae_target_two': fpr_vae_target_two,\n",
    "    'tpr_vae_target_two': tpr_vae_target_two,\n",
    "    'tpr_1em5_vae_target_two': tpr_1em5_vae_target_two,\n",
    "    'auc_vae_target_two': auc_vae_target_two,\n",
    "    'k_prime_vae': k_prime_vae,\n",
    "    'fpr_pca_two': fpr_pca_two,\n",
    "    'tpr_pca_two': tpr_pca_two,\n",
    "    'tpr_1em5_pca_two': tpr_1em5_pca_two,\n",
    "    'auc_pca_two': auc_pca_two,\n",
    "    'fpr_pca_three': fpr_pca_three,\n",
    "    'tpr_pca_three': tpr_pca_three,\n",
    "    'tpr_1em5_pca_three': tpr_1em5_pca_three,\n",
    "    'auc_pca_three': auc_pca_three,\n",
    "    'fpr_pca_four': fpr_pca_four,\n",
    "    'tpr_pca_four': tpr_pca_four,\n",
    "    'tpr_1em5_pca_four': tpr_1em5_pca_four,\n",
    "    'auc_pca_four': auc_pca_four,\n",
    "    'fpr_pca_target': fpr_pca_target,\n",
    "    'tpr_pca_target': tpr_pca_target,\n",
    "    'tpr_1em5_pca_target': tpr_1em5_pca_target,\n",
    "    'auc_pca_target': auc_pca_target,\n",
    "    'k_pca': k_pca,\n",
    "    'fpr_pca_target_two': fpr_pca_target_two,\n",
    "    'tpr_pca_target_two': tpr_pca_target_two,\n",
    "    'tpr_1em5_pca_target_two': tpr_1em5_pca_target_two,\n",
    "    'auc_pca_target_two': auc_pca_target_two,\n",
    "    'k_prime_pca': k_prime_pca,\n",
    "}\n",
    "\n",
    "roc_file = \"roc_variables.pkl\"\n",
    "# Save variables to a file\n",
    "with open(roc_file, \"wb\") as file:\n",
    "    pickle.dump(roc_variables, file)\n",
    "\n",
    "print(f\"ROC variables saved to {roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fea29-914c-4c6e-9b74-acf3f589da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the requirements.txt\n",
    "try:\n",
    "   with open(\"requirements.txt\", \"w\") as f:\n",
    "       subprocess.run([\"pip\", \"freeze\"], stdout=f, check=True)\n",
    "   print(\"requirements.txt saved successfully!\")\n",
    "except Exception as e:\n",
    "   print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
