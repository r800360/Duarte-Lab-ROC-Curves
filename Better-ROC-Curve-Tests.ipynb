{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a23fe-daeb-4422-8f0a-0f5403dc8ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in /opt/conda/lib/python3.11/site-packages (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (0.59.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from umap-learn) (4.66.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.4.0)\n",
      "Requirement already satisfied: mplhep in /opt/conda/lib/python3.11/site-packages (0.3.55)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /opt/conda/lib/python3.11/site-packages (from mplhep) (3.8.4)\n",
      "Requirement already satisfied: mplhep-data>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from mplhep) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from mplhep) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from mplhep) (24.0)\n",
      "Requirement already satisfied: uhi>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from mplhep) (0.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->mplhep) (1.16.0)\n",
      "Requirement already satisfied: psycopg2-binary in ./.local/lib/python3.11/site-packages (2.9.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 22:25:16.878655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: psycopg2-binary\n",
      "Version: 2.9.10\n",
      "Summary: psycopg2 - Python-PostgreSQL Database Adapter\n",
      "Home-page: https://psycopg.org/\n",
      "Author: Federico Di Gregorio\n",
      "Author-email: fog@initd.org\n",
      "License: LGPL with exceptions\n",
      "Location: /home/jovyan/.local/lib/python3.11/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "#Necessary Imports\n",
    "import os\n",
    "#os.system(\"pip freeze > requirements.txt\")\n",
    "#os.system(\"pip install -r requirements.txt\")\n",
    "os.system(\"pip install umap-learn\")\n",
    "os.system(\"pip install mplhep\")\n",
    "os.system(\"pip install psycopg2-binary --user\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import dask.array as da\n",
    "\n",
    "import tensorflow as tf\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "from umap.parametric_umap import ParametricUMAP as PUMAP\n",
    "import sys\n",
    "os.system(\"pip show psycopg2-binary\")\n",
    "sys.path.append(\"/home/jovyan/.local/lib/python3.11/site-packages\")\n",
    "\n",
    "import psycopg2\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d4a294-b68d-400f-91c5-d5cf60731497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(host=\"adc-2021.c7skue2e0u6i.us-east-1.rds.amazonaws.com\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"UM#37tz;80\",\n",
    "                        port=\"5432\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Set the schema to be used\n",
    "cur.execute(\"SET search_path TO l1anomaly\")\n",
    "# random_background_indices = np.random.choice(2000000, size=2000000, replace=False)\n",
    "# random_signal_indices = np.random.choice(600000, size=600000, replace=False)\n",
    "random_background_indices = np.random.choice(1000, size=1000, replace=False)\n",
    "random_signal_indices = np.random.choice(1000, size=1000, replace=False)\n",
    "# Convert numpy arrays to comma-separated strings\n",
    "random_background_indices_str = ', '.join(map(str, random_background_indices))\n",
    "random_signal_indices_str = ', '.join(map(str, random_signal_indices))\n",
    "\n",
    "cur.execute(f\"SELECT * FROM background_for_training WHERE idbackground_for_training IN ({random_background_indices_str})\")\n",
    "background_data = cur.fetchall()\n",
    "\n",
    "cur.execute(f\"SELECT * FROM hToTauTau_13TeV_PU20_filtered WHERE idhToTauTau_13TeV_PU20_filtered IN ({random_signal_indices_str})\")\n",
    "signal_data = cur.fetchall()\n",
    "\n",
    "background_data = np.array(background_data)\n",
    "signal_data = np.array(signal_data)\n",
    "\n",
    "#Let's try getting the data in with batching\n",
    "\n",
    "# Function to query in batches and collect data\n",
    "# def fetch_data_in_batches(cursor, table_name, id_column, id_list, batch_size=10000):\n",
    "#     data = []\n",
    "#     for i in range(0, len(id_list), batch_size):\n",
    "#         # Extract the current batch of IDs\n",
    "#         batch = id_list[i:i + batch_size]\n",
    "#         batch_str = ', '.join(map(str, batch))\n",
    "        \n",
    "#         # Execute the query for the current batch\n",
    "#         query = f\"SELECT * FROM {table_name} WHERE {id_column} IN ({batch_str})\"\n",
    "#         print(\"Query: \" + str(i))\n",
    "#         cursor.execute(query)\n",
    "        \n",
    "#         # Fetch and extend the data list\n",
    "#         data.extend(cursor.fetchall())\n",
    "#     return np.array(data)\n",
    "\n",
    "# Connect to the database\n",
    "# conn = psycopg2.connect(host=\"adc-2021.c7skue2e0u6i.us-east-1.rds.amazonaws.com\",\n",
    "#                         user=\"postgres\",\n",
    "#                         password=\"UM#37tz;80\",\n",
    "#                         port=\"5432\")\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# Set the schema to be used\n",
    "# cur.execute(\"SET search_path TO l1anomaly\")\n",
    "\n",
    "# Generate random indices for background and signal\n",
    "# random_background_indices = np.random.choice(13000000, size=3000000, replace=False)\n",
    "# random_signal_indices = np.random.choice(690000, size=690000, replace=False)\n",
    "\n",
    "# Fetch background data in batches\n",
    "# background_data = fetch_data_in_batches(\n",
    "#     cur,\n",
    "#     table_name=\"background_for_training\",\n",
    "#     id_column=\"idbackground_for_training\",\n",
    "#     id_list=random_background_indices,\n",
    "#     batch_size=500000  # Adjust batch size as needed\n",
    "# )\n",
    "\n",
    "# # Fetch signal data in batches\n",
    "# signal_data = fetch_data_in_batches(\n",
    "#     cur,\n",
    "#     table_name=\"hToTauTau_13TeV_PU20_filtered\",\n",
    "#     id_column=\"idhToTauTau_13TeV_PU20_filtered\",\n",
    "#     id_list=random_signal_indices,\n",
    "#     batch_size=100000\n",
    "# )\n",
    "\n",
    "# Signal label\n",
    "signal_label = \"$h^{{0}} \\\\to \\\\tau\\\\tau$\"\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cddc63e-bcc1-4ff8-9a78-88ea86608285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def mse_loss(inputs, outputs):\n",
    "    #Mean distance squared between input and output tensors\n",
    "    return tf.math.reduce_mean((inputs - outputs) ** 2, axis=-1)\n",
    "\n",
    "# def make_mse_per_sample(inputs, outputs):\n",
    "#     outputs = tf.cast(outputs, dtype=inputs.dtype)  # make same type\n",
    "\n",
    "#     inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "#     outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "#     # extract pt\n",
    "#     outputs_pt = outputs[:, :, 0]\n",
    "\n",
    "#     # trick with phi (rescaled tanh activation function)\n",
    "#     outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "#     # trick with eta (rescaled tanh activation function)\n",
    "#     outputs_eta_met = outputs[:, 0:1, 1]\n",
    "#     outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "#         outputs[:, ele_off : ele_off + nele, 1]\n",
    "#     )\n",
    "#     outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "#     outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "#         outputs[:, jet_off : jet_off + njet, 1]\n",
    "#     )\n",
    "#     outputs_eta = tf.concat(\n",
    "#         [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "#     )\n",
    "\n",
    "#     # use both tricks\n",
    "#     outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi], axis=-1)\n",
    "\n",
    "#     # mask zero features\n",
    "#     mask = tf.math.not_equal(inputs, 0)\n",
    "#     mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "#     outputs = mask * outputs\n",
    "\n",
    "#     loss = mse_loss(\n",
    "#         tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "#         tf.reshape(outputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "#     )\n",
    "#     return loss\n",
    "\n",
    "def make_mse_per_sample(inputs, outputs):\n",
    "    outputs = tf.cast(outputs, dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "\n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = outputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = outputs[:, :, 3]\n",
    "\n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = outputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        outputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        outputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "    outputs = mask * outputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (nmet + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(outputs, [-1, (nmet + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def make_mse(inputs, outputs):\n",
    "    loss = make_mse_per_sample(inputs, outputs)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def scale_pt(X, pt_scaler=None):\n",
    "    pt = X[:, 0::nfeat]\n",
    "    if pt_scaler is None:\n",
    "        pt_scaler = StandardScaler()\n",
    "        pt_scaled = pt_scaler.fit_transform(pt)\n",
    "    else:\n",
    "        pt_scaled = pt_scaler.transform(pt)\n",
    "    X_scaled = np.copy(X)\n",
    "    X_scaled[:, 0::nfeat] = np.multiply(pt_scaled, pt != 0)\n",
    "    return X_scaled, pt_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e535a7-b552-4acc-804a-3b35982bc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamental Constants\n",
    "\n",
    "nfeat = 4\n",
    "nmet = 1\n",
    "nele = 4\n",
    "nmu = 4\n",
    "njet = 10\n",
    "ele_off = 1\n",
    "mu_off = nmet + nele\n",
    "jet_off = nmet + nele + nmu\n",
    "phi_max = np.pi\n",
    "ele_eta_max = 3.0\n",
    "mu_eta_max = 2.1\n",
    "jet_eta_max = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eade1629-1de5-4922-8aa2-1d1c19588583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start with Gaussian\n",
    "# background_data_reduced, extraneous = train_test_split(background_data, test_size = 0.5)\n",
    "\n",
    "\n",
    "X_train_val, X_test = train_test_split(background_data.reshape(background_data.shape[0], -1), test_size=0.2, shuffle=True)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.2, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "merged_data = np.concatenate([X_test, signal_data], axis=0)\n",
    "merged_labels = np.concatenate([np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0)\n",
    "merged_data_trans = scaler.transform(merged_data)\n",
    "merged_loss = np.sum(merged_data_trans ** 2, axis=-1)\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_gaussian = fpr\n",
    "tpr_gaussian = tpr\n",
    "tpr_1em5_gaussian = tpr_1em5\n",
    "auc_gaussian = auc\n",
    "plt.plot(fpr_gaussian, tpr_gaussian, label=f\"Gaussian, AUC={auc(fpr_gaussian, tpr_gaussian)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_gaussian[tpr_1em5_gaussian]*100:.3f}%\")\n",
    "plt.legend(title = str(signal_label) +\" baseline\")\n",
    "plt.plot([1e-6, 1], [1e-6, 1], 'k--')\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], 'r-.')\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fb2b4d-777b-4203-a41e-6902e13e229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue with PUMAP\n",
    "X_train_scaled, pt_scaler = scale_pt(X_train)\n",
    "\n",
    "X_test_scaled, _ = scale_pt(X_test, pt_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b627ed3-eed9-4357-9caa-5aa318c7353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_pumap(X_scaled,inv_transform_data):\n",
    "    #Extract loss from model predictions using make_mse_per_sample function analyzed above\n",
    "    return np.array(make_mse_per_sample(X_scaled, inv_transform_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921b8689-4044-4300-a01b-2434f81ba377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_pca(X_scaled,inv_transform_data):\n",
    "    #Extract loss from model predictions using make_mse_per_sample function analyzed above\n",
    "    return np.array(make_mse_per_sample(X_scaled, inv_transform_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ba5024-b505-4a69-8cbb-6013db7454fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dask array from the full dataset\n",
    "# X_train_scaled_dask = da.from_array(X_train_scaled, chunks=(1_000_000, X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e380deff-94d4-48e5-beac-de09bd9fb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = PUMAP(low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42415d3-0182-4a79-8ee4-d39510a5adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'umap_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2401\n",
      "Epoch 2/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2109\n",
      "Epoch 3/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2055\n",
      "Epoch 4/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2031\n",
      "Epoch 5/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2008\n",
      "Epoch 6/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1996\n",
      "Epoch 7/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1988\n",
      "Epoch 8/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1988\n",
      "Epoch 9/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1981\n",
      "Epoch 10/10\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1986\n"
     ]
    }
   ],
   "source": [
    "trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "# We fit the entire dataset at once (but it’s done in chunks internally)\n",
    "# This will avoid multiple fit calls but still scale efficiently\n",
    "# trainEmbedding = model.fit_transform(X_train_scaled_dask.compute())\n",
    "# inv_transform_training_data = model.inverse_transform(trainEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c7afc0-cbe0-40bc-b848-d5fb26f22623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform in batches (to avoid memory overload)\n",
    "# batch_size = 1_000_000  # Adjust based on available memory\n",
    "# num_batches = len(trainEmbedding) // batch_size + 1\n",
    "\n",
    "# inv_transform_training_data = []\n",
    "\n",
    "# for i in range(num_batches):\n",
    "#     start = i * batch_size\n",
    "#     end = min((i + 1) * batch_size, len(trainEmbedding))\n",
    "#     print(f\"Inverse transforming batch {i + 1}/{num_batches}\")\n",
    "#     inv_batch = model.inverse_transform(trainEmbedding[start:end])\n",
    "#     inv_transform_training_data.append(inv_batch)\n",
    "\n",
    "# # Combine batches into a single array\n",
    "# inv_transform_training_data = np.vstack(inv_transform_training_data)\n",
    "inv_transform_training_data = model.inverse_transform(trainEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af727a8-5c42-4a21-a4e8-9193760912b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 77)\n"
     ]
    }
   ],
   "source": [
    "print((X_train_scaled).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd6c793a-68c5-4c1e-94c2-484c6a2e21d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PUMAP signal embedding: $h^{{0}} \\to \\tau\\tau$\n",
      "Successful PUMAP signal embedding, inverse transform, and loss computations: $h^{{0}} \\to \\tau\\tau$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "background_loss = get_loss_pumap(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "merged_labels = np.concatenate(\n",
    "    [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    ")\n",
    "\n",
    "print(\"Starting PUMAP signal embedding: \" + signal_label)\n",
    "inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "\n",
    "signal_loss = get_loss_pumap(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "\n",
    "print(\"Successful PUMAP signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_pumap = fpr\n",
    "tpr_pumap = tpr\n",
    "tpr_1em5_pumap = tpr_1em5\n",
    "auc_pumap = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08fa2e0d-5251-4c36-8a66-4e21d8cb910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "model = PCA(n_components=10)\n",
    "\n",
    "trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "inv_transform_training_data = model.inverse_transform(trainEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e82335ba-b1dd-40b5-a2f1-f96374eb9bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PCA signal embedding: $h^{{0}} \\to \\tau\\tau$\n",
      "Successful PCA signal embedding, inverse transform, and loss computations: $h^{{0}} \\to \\tau\\tau$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "background_loss = get_loss_pca(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "merged_labels = np.concatenate(\n",
    "    [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    ")\n",
    "\n",
    "print(\"Starting PCA signal embedding: \" + signal_label)\n",
    "inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "\n",
    "signal_loss = get_loss_pca(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "\n",
    "print(\"Successful PCA signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_pca = fpr\n",
    "tpr_pca = tpr\n",
    "tpr_1em5_pca = tpr_1em5\n",
    "auc_pca = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8c7e53-09e8-4ad6-b104-72f2615d92e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mse_per_sample_ae_class(inputs, outputs):\n",
    "        outputs = tf.cast(outputs, dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "\n",
    "        #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "        # as in Main AE paper\n",
    "        inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "        outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "        # extract pt\n",
    "        outputs_pt = outputs[:, :, 0]\n",
    "        \n",
    "        # extract class\n",
    "        outputs_class = outputs[:, :, 3]\n",
    "\n",
    "        # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "        outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "        #Extracts missing transverse energy pseudorapidity outputs\n",
    "        outputs_eta_met = outputs[:, 0:1, 1]\n",
    "\n",
    "        # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "        outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "            outputs[:, ele_off : ele_off + nele, 1]\n",
    "        )\n",
    "\n",
    "        #Treatment of muon pseudorapidity analogous to that of electron\n",
    "        outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "        #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "        outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "            outputs[:, jet_off : jet_off + njet, 1]\n",
    "        )\n",
    "\n",
    "        #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "        outputs_eta = tf.concat(\n",
    "            [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "        )\n",
    "\n",
    "        # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "        outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "        # mask zero features - Zero Padding after output formation\n",
    "        mask = tf.math.not_equal(inputs, 0)\n",
    "        mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "        outputs = mask * outputs\n",
    "\n",
    "        #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "        loss = mse_loss(\n",
    "            tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "            tf.reshape(outputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        )\n",
    "        \n",
    "        return loss\n",
    "\n",
    "def make_mse_ae(inputs, outputs):\n",
    "    loss = make_mse_per_sample_ae_class(inputs, outputs)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad36882c-3aed-4d95-b3a9-c3bc2a605db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_ae(X, X_scaled):\n",
    "    return np.array(make_mse_per_sample_ae_class(X_scaled, model.predict(X, batch_size=1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fcba64b-ac4d-46dd-9d9b-075b30ddbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled, _ = scale_pt(X_val, pt_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae98873c-9820-453a-9793-147c88deaf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76,)\n"
     ]
    }
   ],
   "source": [
    "print((X_train[:, 1:].shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f05ccb7a-a9bd-4f67-a402-cafd1c3cba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 90.9828 - val_loss: 90.9736 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 90.9813 - val_loss: 89.8431 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 90.9798 - val_loss: 89.2515 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 90.9783 - val_loss: 88.8591 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 90.9768 - val_loss: 88.5605 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 90.9754 - val_loss: 88.3211 - learning_rate: 1.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 90.9739 - val_loss: 88.1222 - learning_rate: 1.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 90.9724 - val_loss: 87.9466 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 90.9709 - val_loss: 87.7976 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 90.9695 - val_loss: 87.6667 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8545b88b10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, TensorBoard\n",
    "import datetime\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=2,\n",
    "        min_lr=1e-6,\n",
    "    ),\n",
    "    TerminateOnNaN(),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\", verbose=1, patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=(\"./VAELOGS\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    ),\n",
    "]\n",
    "\n",
    "inputs = Input(shape=(X_train[:, 1:].shape[1],))\n",
    "\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(3, kernel_initializer=HeUniform())(x)\n",
    "x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "outputs = Dense(X_train[:, 1:].shape[1], kernel_initializer=HeUniform())(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss=make_mse_ae)\n",
    "model.fit(\n",
    "    X_train[:, 1:],\n",
    "    X_train_scaled[:, 1:],\n",
    "    epochs=10,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_val[:, 1:], X_val_scaled[:, 1:]),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2aaf381-2678-4251-b9bb-cd706fef9ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "background_loss = get_loss_ae(X_test[:, 1:], X_test_scaled[:, 1:])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "merged_labels = np.concatenate(\n",
    "    [np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    ")\n",
    "signal_loss = get_loss_ae(signal_data[:, 1:], signal_data_scaled[:, 1:])\n",
    "merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_ae = fpr\n",
    "tpr_ae = tpr\n",
    "tpr_1em5_ae = tpr_1em5\n",
    "auc_ae = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59964d0f-c059-47b2-9bff-9d2363d1ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mse_per_sample_vae_class(inputs, outputs, latent_dimension):\n",
    "    mainOutputs = tf.cast(outputs[:, latent_dimension:-latent_dimension], dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "    meanLatentSpaceVector = outputs[:, :latent_dimension]\n",
    "    logVarVector = outputs[:, -latent_dimension:]\n",
    "    beta = 0.5\n",
    "    klDivCoef = (beta) * -0.5\n",
    "    \n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    mainOutputs = tf.reshape(mainOutputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = mainOutputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = mainOutputs[:, :, 3]\n",
    "    \n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(mainOutputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = mainOutputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(mainOutputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    mainOutputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=mainOutputs.dtype)\n",
    "    mainOutputs = mask * mainOutputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    mse_loss_value = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(mainOutputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    mse_loss_value = tf.math.reduce_mean(mse_loss_value, axis=0)\n",
    "    \n",
    "    kl_divergence = tf.math.multiply(klDivCoef, tf.reduce_sum(1 + logVarVector - tf.square(meanLatentSpaceVector) - tf.exp(logVarVector), axis=-1))\n",
    "    kl_divergence = tf.math.reduce_mean(kl_divergence, axis=0)\n",
    "    kl_divergence = tf.cast(kl_divergence, dtype = mse_loss_value.dtype)\n",
    "\n",
    "    # Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = tf.math.add(tf.math.multiply((1 - beta), mse_loss_value), kl_divergence)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def make_mse_vae(inputs, outputs):\n",
    "    loss = make_mse_per_sample_vae_class(inputs, outputs, latent_dim)\n",
    "\n",
    "    #loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def mod_make_mse_per_sample_vae_class(inputs, outputs, latent_dimension):\n",
    "    mainOutputs = tf.cast(outputs[:, latent_dimension:-latent_dimension], dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "    meanLatentSpaceVector = outputs[:, :latent_dimension]\n",
    "    logVarVector = outputs[:, -latent_dimension:]\n",
    "    beta = 0.5\n",
    "    klDivCoef = (beta) * -0.5\n",
    "    \n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    mainOutputs = tf.reshape(mainOutputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = mainOutputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = mainOutputs[:, :, 3]\n",
    "    \n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(mainOutputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = mainOutputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(mainOutputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    mainOutputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=mainOutputs.dtype)\n",
    "    mainOutputs = mask * mainOutputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    mse_loss_value = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(mainOutputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    #mse_loss_value = tf.math.reduce_mean(mse_loss_value, axis=0)\n",
    "    \n",
    "    kl_divergence = tf.math.multiply(klDivCoef, tf.reduce_sum(1 + logVarVector - tf.square(meanLatentSpaceVector) - tf.exp(logVarVector), axis=-1))\n",
    "    #kl_divergence = tf.math.reduce_mean(kl_divergence, axis=0)\n",
    "    kl_divergence = tf.cast(kl_divergence, dtype = mse_loss_value.dtype)\n",
    "\n",
    "    # Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = tf.math.add(tf.math.multiply((1 - beta), mse_loss_value), kl_divergence)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9deb6bda-2cd6-467c-a5bb-34f7687cf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_vae(X, X_scaled):\n",
    "    return np.array(mod_make_mse_per_sample_vae_class(X_scaled, model.predict(X, batch_size=1024), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ab62522-0130-4357-bd03-877cfe3f1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cac345f-e0dd-42a2-a52e-15a70912801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m     71\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m), loss\u001b[38;5;241m=\u001b[39mmake_mse_vae)\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 889\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:122\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 122\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    126\u001b[0m     outputs,\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    128\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:906\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    911\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    912\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:57\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_has_training_arg:\n\u001b[0;32m---> 57\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:826\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    830\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/models/functional.py:199\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 199\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/ops/function.py:151\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mfill_in(tensor_dict)\n\u001b[0;32m--> 151\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/models/functional.py:583\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    581\u001b[0m ):\n\u001b[1;32m    582\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:826\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    830\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/lambda_layer.py:120\u001b[0m, in \u001b[0;36mLambda.call\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fn_expects_training_arg:\n\u001b[1;32m    119\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m, in \u001b[0;36msampling\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msampling\u001b[39m(args):\n\u001b[1;32m      5\u001b[0m     mean, log_var \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m----> 6\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m log_var) \u001b[38;5;241m*\u001b[39m epsilon\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/random_ops.py:88\u001b[0m, in \u001b[0;36mrandom_normal\u001b[0;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m shape_tensor \u001b[38;5;241m=\u001b[39m shape_util\u001b[38;5;241m.\u001b[39mshape_tensor(shape)\n\u001b[1;32m     87\u001b[0m mean_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m stddev_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstddev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m seed1, seed2 \u001b[38;5;241m=\u001b[39m random_seed\u001b[38;5;241m.\u001b[39mget_seed(seed)\n\u001b[1;32m     90\u001b[0m rnd \u001b[38;5;241m=\u001b[39m gen_random_ops\u001b[38;5;241m.\u001b[39mrandom_standard_normal(\n\u001b[1;32m     91\u001b[0m     shape_tensor, dtype, seed\u001b[38;5;241m=\u001b[39mseed1, seed2\u001b[38;5;241m=\u001b[39mseed2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:291\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_broadcast\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:276\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m g \u001b[38;5;241m=\u001b[39m get_default_graph()\n\u001b[1;32m    274\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n\u001b[1;32m    275\u001b[0m tensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mCopyFrom(\n\u001b[0;32m--> 276\u001b[0m     \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_tensor_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    279\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    280\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/tensor_util.py:627\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    626\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElement type not supported in TensorProto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 627\u001b[0m \u001b[43mappend_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_proto\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/tensor_util.py:167\u001b[0m, in \u001b[0;36mSlowAppendFloat32ArrayToTensorProto\u001b[0;34m(tensor_proto, proto_values)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSlowAppendFloat32ArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[0;32m--> 167\u001b[0m   tensor_proto\u001b[38;5;241m.\u001b[39mfloat_val\u001b[38;5;241m.\u001b[39mextend([x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Concatenate\n",
    "\n",
    "# Custom sampling layer to generate epsilon and compute z\n",
    "def sampling(args):\n",
    "    mean, log_var = args\n",
    "    epsilon = tf.random.normal(tf.shape(mean), mean=0.0, stddev=1.0)\n",
    "    return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "    \n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=2,\n",
    "        min_lr=1e-6,\n",
    "    ),\n",
    "    TerminateOnNaN(),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\", verbose=1, patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=(\"./VAELOGS\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    ),\n",
    "]\n",
    "\n",
    "inputs = Input(shape=(X_train[:, 1:].shape[1],))\n",
    "\n",
    "x = BatchNormalization()(inputs)\n",
    "#Block 1\n",
    "x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "\n",
    "#Block 2\n",
    "x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "\n",
    "#Block 3\n",
    "x = Dense(latent_dim, kernel_initializer=HeUniform())(x)\n",
    "meanLatentSpaceVector = Dense(3, activation='linear')(x)\n",
    "logVarVector = Dense(3, activation='linear')(x)\n",
    "# epsilon = tf.random.normal(tf.shape(meanLatentSpaceVector), mean=0.0, stddev=1.0)\n",
    "# z = meanLatentSpaceVector + tf.exp(0.5 * logVarVector) * epsilon\n",
    "z = Lambda(sampling)([meanLatentSpaceVector, logVarVector])\n",
    "\n",
    "intermediate = z\n",
    "\n",
    "# Block 4\n",
    "z = Dense(16, kernel_initializer=HeUniform())(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU(alpha=0.3)(z)\n",
    "\n",
    "# Block 5\n",
    "z = Dense(32, kernel_initializer=HeUniform())(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU(alpha=0.3)(z)\n",
    "\n",
    "# decoderEpsilon = tf.random.normal(tf.shape(meanLatentSpaceVector), mean=0.0, stddev=1.0)\n",
    "# decoderZ = meanLatentSpaceVector + tf.exp(0.5 * logVarVector) * decoderEpsilon\n",
    "\n",
    "# Output Layer\n",
    "outputs = Dense(X_train[:, 1:].shape[1], kernel_initializer=HeUniform())(z)\n",
    "outputs = Concatenate(axis=1)([meanLatentSpaceVector, outputs, logVarVector])\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss=make_mse_vae)\n",
    "model.fit(\n",
    "    X_train[:, 1:],\n",
    "    X_train_scaled[:, 1:],\n",
    "    epochs=10,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_val[:, 1:], X_val_scaled[:, 1:]),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744dc0c-372c-470d-bb32-b60873588bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_loss = get_loss_vae(X_test[:, 1:], X_test_scaled[:, 1:])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "merged_labels = np.concatenate(\n",
    "    [np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    ")\n",
    "signal_loss = get_loss_vae(signal_data[:, 1:], signal_data_scaled[:, 1:])\n",
    "merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_vae = fpr\n",
    "tpr_vae = tpr\n",
    "tpr_1em5_vae = tpr_1em5\n",
    "auc_vae = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba15f76-48b9-484e-aea0-07d5ab76cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_gaussian,\n",
    "         tpr_gaussian,\n",
    "         label=f\"Gaussian, AUC={auc(fpr_gaussian, tpr_gaussian)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_gaussian[tpr_1em5_gaussian]*100:.3f}%\")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_pumap,\n",
    "    tpr_pumap,\n",
    "    label=f\"PUMAP, AUC={auc(fpr_pumap, tpr_pumap)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pumap[tpr_1em5_pumap]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_pca,\n",
    "    tpr_pca,\n",
    "    label=f\"PCA-10, AUC={auc(fpr_pca, tpr_pca)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca[tpr_1em5_pca]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_ae,\n",
    "    tpr_ae,\n",
    "    label=f\"DNNAE, AUC={auc(fpr_ae, tpr_ae)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_ae[tpr_1em5_ae]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_vae,\n",
    "    tpr_vae,\n",
    "    label=f\"DNNVAE, AUC={auc(fpr_vae, tpr_vae)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_vae[tpr_1em5_vae]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.legend(title=f\"{signal_label} Baseline\")\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68764c35-43a9-47e9-87f3-8334988706b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc as auc\n",
    "def PCA_ROC(signal_data, n_comp):\n",
    "    model = PCA(n_components=n_comp)\n",
    "    \n",
    "    trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "    inv_transform_training_data = model.inverse_transform(trainEmbedding)\n",
    "    background_loss = get_loss_pca(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "    \n",
    "    # _ = plt.figure()\n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    \n",
    "    # print(\"Starting PCA signal embedding: \" + signal_label)\n",
    "    inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "    \n",
    "    signal_loss = get_loss_pca(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "    # print(\"Successful PCA signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a76a75-cd3e-4fb0-8110-7b6c2cd49882",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, auc_pca_two) = PCA_ROC(signal_data, 2)\n",
    "(fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, auc_pca_three) = PCA_ROC(signal_data, 3)\n",
    "(fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, auc_pca_four) = PCA_ROC(signal_data, 4)\n",
    "(fpr_pca_eight, tpr_pca_eight, tpr_1em5_pca_eight, auc_pca_eight) = PCA_ROC(signal_data, 8)\n",
    "(fpr_pca_ten, tpr_pca_ten, tpr_1em5_pca_ten, auc_pca_ten) = PCA_ROC(signal_data, 10)\n",
    "(fpr_pca_twelve, tpr_pca_twelve, tpr_1em5_pca_twelve, auc_pca_twelve) = PCA_ROC(signal_data, 12)\n",
    "(fpr_pca_thirteen, tpr_pca_thirteen, tpr_1em5_pca_thirteen, auc_pca_thirteen) = PCA_ROC(signal_data, 13)\n",
    "(fpr_pca_sixteen, tpr_pca_sixteen, tpr_1em5_pca_sixteen, auc_pca_sixteen) = PCA_ROC(signal_data, 16)\n",
    "(fpr_pca_thirtytwo, tpr_pca_thirtytwo, tpr_1em5_pca_thirtytwo, auc_pca_thirtytwo) = PCA_ROC(signal_data, 32)\n",
    "(fpr_pca_sixtyfour, tpr_pca_sixtyfour, tpr_1em5_pca_sixtyfour, auc_pca_sixtyfour) = PCA_ROC(signal_data, 64)\n",
    "(fpr_pca_seventy, tpr_pca_seventy, tpr_1em5_pca_seventy, auc_pca_seventy) = PCA_ROC(signal_data, 70)\n",
    "(fpr_pca_seventysix, tpr_pca_seventysix, tpr_1em5_pca_seventysix, auc_pca_seventysix) = PCA_ROC(signal_data, 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e6e04-9555-4f4a-9862-9446c4a97381",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dict = {}\n",
    "tpr_1em5_dict = {}\n",
    "\n",
    "for i in range(2, 77):\n",
    "    (fpr_pca_test, tpr_pca_test, tpr_1em5_pca_test, auc_pca_test) = PCA_ROC(signal_data, i)\n",
    "    auc_dict[i] = auc_pca_test\n",
    "    tpr_1em5_dict[i] = tpr_1em5_pca_test\n",
    "\n",
    "sorted_dict_auc = dict(sorted(auc_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_dict_tpr_1em5 = dict(sorted(tpr_1em5_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc in sorted_dict_auc.items():\n",
    "    tpr_1em5 = sorted_dict_tpr_1em5[n_components]\n",
    "    print(f\"{n_components:<15} {auc*100:.2f}% {tpr_1em5*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9cd8d-e32d-4d03-9ff3-cfa6c82ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from matplotlib.legend import Legend\n",
    "from sklearn.metrics import auc as auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "def plot_PCA(fpr_pca, tpr_pca, tpr_1em5_pca, auc_pca, n_comp):\n",
    "    plt.plot(\n",
    "        fpr_pca,\n",
    "        tpr_pca,\n",
    "        label=f\"PCA-{n_comp}, AUC={auc(fpr_pca, tpr_pca)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca[tpr_1em5_pca]*100:.3f}%\",\n",
    "    )\n",
    "\n",
    "# Add your data for plotting\n",
    "plot_PCA(fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, auc_pca_two, 2)\n",
    "plot_PCA(fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, auc_pca_three, 3)\n",
    "plot_PCA(fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, auc_pca_four, 4)\n",
    "plot_PCA(fpr_pca_eight, tpr_pca_eight, tpr_1em5_pca_eight, auc_pca_eight, 8)\n",
    "plot_PCA(fpr_pca_ten, tpr_pca_ten, tpr_1em5_pca_ten, auc_pca_ten, 10)\n",
    "plot_PCA(fpr_pca_twelve, tpr_pca_twelve, tpr_1em5_pca_twelve, auc_pca_twelve, 12)\n",
    "plot_PCA(fpr_pca_thirteen, tpr_pca_thirteen, tpr_1em5_pca_thirteen, auc_pca_thirteen, 13)\n",
    "plot_PCA(fpr_pca_sixteen, tpr_pca_sixteen, tpr_1em5_pca_sixteen, auc_pca_sixteen, 16)\n",
    "plot_PCA(fpr_pca_thirtytwo, tpr_pca_thirtytwo, tpr_1em5_pca_thirtytwo, auc_pca_thirtytwo, 32)\n",
    "plot_PCA(fpr_pca_sixtyfour, tpr_pca_sixtyfour, tpr_1em5_pca_sixtyfour, auc_pca_sixtyfour, 64)\n",
    "plot_PCA(fpr_pca_seventy, tpr_pca_seventy, tpr_1em5_pca_seventy, auc_pca_seventy, 70)\n",
    "plot_PCA(fpr_pca_seventysix, tpr_pca_seventysix, tpr_1em5_pca_seventysix, auc_pca_seventysix, 76)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "# Save the main plot without the legend\n",
    "pca_roc_file_name = f\"New-PCA-ROC-Curve-B{random_background_indices.size}-S{random_signal_indices.size}\"\n",
    "plt.savefig(f\"{pca_roc_file_name}.png\", format='png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Create a separate figure for the legend\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))  # Adjust the figure size\n",
    "# legend_fig = ax.legend_ = legend  # Use the existing legend\n",
    "# ax.axis(\"off\")  # Turn off axes for the legend figure\n",
    "\n",
    "# # Save the legend as a separate image\n",
    "# legend_file_name = f\"{roc_file_name}_legend.png\"\n",
    "# fig.savefig(legend_file_name, format='png', dpi=300, bbox_inches='tight')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad5193-e1ca-4140-88a3-d5a2fd23356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = max(sorted_dict_auc, key=sorted_dict_auc.get)\n",
    "k_prime = max(sorted_dict_tpr_1em5, key=sorted_dict_tpr_1em5.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6bdf9-6959-43a2-bf93-68e01248f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k)\n",
    "print(k_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb2987-6ea4-4898-9878-d8f00a5342d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get PCA-2, PCA-3, PCA-4, PCA with max AUC, PCA with max TPR@FPR 10^-5\n",
    "\n",
    "(fpr_pca_target, tpr_pca_target, tpr_1em5_pca_target, auc_pca_target) = PCA_ROC(signal_data, k)\n",
    "(fpr_pca_target_two, tpr_pca_target_two, tpr_1em5_pca_target_two, auc_pca_target_two) = PCA_ROC(signal_data, k_prime)\n",
    "\n",
    "plt.plot(fpr_gaussian,\n",
    "         tpr_gaussian,\n",
    "         label=f\"Gaussian, AUC={auc(fpr_gaussian, tpr_gaussian)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_gaussian[tpr_1em5_gaussian]*100:.3f}%\")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_pumap,\n",
    "    tpr_pumap,\n",
    "    label=f\"PUMAP, AUC={auc(fpr_pumap, tpr_pumap)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pumap[tpr_1em5_pumap]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "#PCA-2\n",
    "\n",
    "plt.plot(\n",
    "    fpr_pca_two,\n",
    "    tpr_pca_two,\n",
    "    label=f\"PCA-2, AUC={auc(fpr_pca_two, tpr_pca_two)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca_two[tpr_1em5_pca_two]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "#PCA-3\n",
    "\n",
    "plt.plot(\n",
    "    fpr_pca_three,\n",
    "    tpr_pca_three,\n",
    "    label=f\"PCA-3, AUC={auc(fpr_pca_three, tpr_pca_three)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca_three[tpr_1em5_pca_three]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "\n",
    "#PCA-4\n",
    "\n",
    "plt.plot(\n",
    "    fpr_pca_four,\n",
    "    tpr_pca_four,\n",
    "    label=f\"PCA-4, AUC={auc(fpr_pca_four, tpr_pca_four)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca_four[tpr_1em5_pca_four]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "\n",
    "#PCA with max AUC\n",
    "plt.plot(\n",
    "    fpr_pca_target,\n",
    "    tpr_pca_target,\n",
    "    label=f\"PCA-{k}, AUC={auc(fpr_pca_target, tpr_pca_target)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca_target[tpr_1em5_pca_target]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "#PCA with max TPR@FPR 10^-5\n",
    "plt.plot(\n",
    "    fpr_pca_target_two,\n",
    "    tpr_pca_target_two,\n",
    "    label=f\"PCA-{k_prime}, AUC={auc(fpr_pca_target_two, tpr_pca_target_two)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca_target_two[tpr_1em5_pca_target_two]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_ae,\n",
    "    tpr_ae,\n",
    "    label=f\"DNNAE, AUC={auc(fpr_ae, tpr_ae)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_ae[tpr_1em5_ae]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_vae,\n",
    "    tpr_vae,\n",
    "    label=f\"DNNVAE, AUC={auc(fpr_vae, tpr_vae)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_vae[tpr_1em5_vae]*100:.3f}%\",\n",
    ")\n",
    "\n",
    "plt.legend(title=f\"{signal_label} Baseline\")\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "roc_file_name = f\"New-ROC-Curve-B{random_background_indices.size}-S{random_signal_indices.size}\"\n",
    "plt.savefig(f\"{roc_file_name}.png\", format='png', dpi=300)  # High resolution\n",
    "plt.close()  # Close the figure to release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdafbc5-4bee-4b41-859a-028ba212b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "from pathlib import Path\n",
    "\n",
    "# Email details\n",
    "sender_email = \"rosachdeva@ucsd.edu\"\n",
    "receiver_email = \"rosachdeva@ucsd.edu\"\n",
    "password = \"uuvo esud bmib fvvk\"  # Use app-specific password if using Gmail\n",
    "\n",
    "# Create the email message\n",
    "msg = EmailMessage()\n",
    "msg['Subject'] = 'Final ROC Curve Results'\n",
    "msg['From'] = sender_email\n",
    "msg['To'] = receiver_email\n",
    "\n",
    "# Attach text content\n",
    "msg.set_content(\"Please find the final ROC curve attached.\")\n",
    "\n",
    "# Add the ROC curve image\n",
    "roc_curve_path = './' + roc_file_name + \".png\"  # Path to the ROC curve image\n",
    "pca_roc_curve_path = './' + pca_roc_file_name + \".png\"  # Path to the PCA ROC curve image\n",
    "if Path(roc_curve_path).exists():\n",
    "    with open(roc_curve_path, 'rb') as img:\n",
    "        img_data = img.read()\n",
    "        msg.add_attachment(img_data, maintype='image', subtype='png', filename=\"roc_curve.png\")\n",
    "else:\n",
    "    print(f\"Error: {roc_curve_path} not found. Ensure the ROC curve image is saved.\")\n",
    "\n",
    "if Path(pca_roc_curve_path).exists():\n",
    "    with open(pca_roc_curve_path, 'rb') as img:\n",
    "        img_data = img.read()\n",
    "        msg.add_attachment(img_data, maintype='image', subtype='png', filename=\"pca_roc_curve.png\")\n",
    "else:\n",
    "    print(f\"Error: {roc_curve_path} not found. Ensure the ROC curve image is saved.\")\n",
    "\n",
    "\n",
    "\n",
    "# Send the email\n",
    "try:\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:  # For Gmail. Use other SMTP servers if needed.\n",
    "        server.login(sender_email, password)\n",
    "        server.send_message(msg)\n",
    "    print(\"Email sent successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error sending email: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fea29-914c-4c6e-9b74-acf3f589da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the requirements.txt\n",
    "try:\n",
    "    with open(\"requirements.txt\", \"w\") as f:\n",
    "        subprocess.run([\"pip\", \"freeze\"], stdout=f, check=True)\n",
    "    print(\"requirements.txt saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
