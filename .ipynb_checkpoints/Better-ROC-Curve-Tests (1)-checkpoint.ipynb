{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a23fe-daeb-4422-8f0a-0f5403dc8ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in /opt/conda/lib/python3.11/site-packages (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (0.59.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.11/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from umap-learn) (4.66.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.4.0)\n",
      "Requirement already satisfied: mplhep in /opt/conda/lib/python3.11/site-packages (0.3.55)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /opt/conda/lib/python3.11/site-packages (from mplhep) (3.8.4)\n",
      "Requirement already satisfied: mplhep-data>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from mplhep) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from mplhep) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from mplhep) (24.0)\n",
      "Requirement already satisfied: uhi>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from mplhep) (0.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->mplhep) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->mplhep) (1.16.0)\n",
      "Requirement already satisfied: psycopg2-binary in ./.local/lib/python3.11/site-packages (2.9.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 02:44:07.182045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: psycopg2-binary\n",
      "Version: 2.9.10\n",
      "Summary: psycopg2 - Python-PostgreSQL Database Adapter\n",
      "Home-page: https://psycopg.org/\n",
      "Author: Federico Di Gregorio\n",
      "Author-email: fog@initd.org\n",
      "License: LGPL with exceptions\n",
      "Location: /home/jovyan/.local/lib/python3.11/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "#Necessary Imports\n",
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
    "#os.system(\"pip freeze > requirements.txt\")\n",
    "#os.system(\"pip install -r requirements.txt\")\n",
    "os.system(\"pip install umap-learn\")\n",
    "os.system(\"pip install mplhep\")\n",
    "os.system(\"pip install psycopg2-binary --user\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import dask.array as da\n",
    "\n",
    "import tensorflow as tf\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "from umap.parametric_umap import ParametricUMAP as PUMAP\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "os.system(\"pip show psycopg2-binary\")\n",
    "sys.path.append(\"/home/jovyan/.local/lib/python3.11/site-packages\")\n",
    "\n",
    "import io\n",
    "import psycopg2\n",
    "import subprocess\n",
    "import pickle\n",
    "# Import necessary libraries\n",
    "from matplotlib.legend import Legend\n",
    "from sklearn.metrics import auc as auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, TensorBoard\n",
    "from keras.layers import Lambda, Concatenate\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e6fc5e-858c-462a-80bd-5716d5d5c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace NaN values with the column median\n",
    "def replace_nan_with_median(data):\n",
    "    \"\"\"Replaces NaN values in each column with the median of the non-NaN values.\"\"\"\n",
    "    for col in range(data.shape[1]):  # Iterate over columns\n",
    "        col_data = data[:, col]\n",
    "        # Compute the median of non-NaN values\n",
    "        non_nan_values = col_data[~np.isnan(col_data)]\n",
    "        if non_nan_values.size > 0:\n",
    "            median_value = np.median(non_nan_values)\n",
    "            # Replace NaN values with the median\n",
    "            col_data[np.isnan(col_data)] = median_value\n",
    "        else:\n",
    "            # If all values are NaN, fill with 0 or a default value\n",
    "            col_data[np.isnan(col_data)] = 0\n",
    "    return data\n",
    "\n",
    "# Function to query in batches and collect data\n",
    "def fetch_data_in_batches(cursor, table_name, id_column, id_list, batch_size=10000):\n",
    "    data = []\n",
    "    for i in range(0, len(id_list), batch_size):\n",
    "        # Extract the current batch of IDs\n",
    "        batch = id_list[i:i + batch_size]\n",
    "        batch_str = ', '.join(map(str, batch))\n",
    "        \n",
    "        # Execute the query for the current batch\n",
    "        query = f\"SELECT * FROM {table_name} WHERE {id_column} IN ({batch_str})\"\n",
    "        print(\"Query: \" + str(i))\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch and extend the data list\n",
    "        data.extend(cursor.fetchall())\n",
    "    return replace_nan_with_median(np.array(data, dtype=float))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def mse_loss(inputs, outputs):\n",
    "    #Mean distance squared between input and output tensors\n",
    "    return tf.math.reduce_mean((inputs - outputs) ** 2, axis=-1)\n",
    "\n",
    "# def make_mse_per_sample(inputs, outputs):\n",
    "#     outputs = tf.cast(outputs, dtype=inputs.dtype)  # make same type\n",
    "\n",
    "#     inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "#     outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "#     # extract pt\n",
    "#     outputs_pt = outputs[:, :, 0]\n",
    "\n",
    "#     # trick with phi (rescaled tanh activation function)\n",
    "#     outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "#     # trick with eta (rescaled tanh activation function)\n",
    "#     outputs_eta_met = outputs[:, 0:1, 1]\n",
    "#     outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "#         outputs[:, ele_off : ele_off + nele, 1]\n",
    "#     )\n",
    "#     outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "#     outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "#         outputs[:, jet_off : jet_off + njet, 1]\n",
    "#     )\n",
    "#     outputs_eta = tf.concat(\n",
    "#         [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "#     )\n",
    "\n",
    "#     # use both tricks\n",
    "#     outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi], axis=-1)\n",
    "\n",
    "#     # mask zero features\n",
    "#     mask = tf.math.not_equal(inputs, 0)\n",
    "#     mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "#     outputs = mask * outputs\n",
    "\n",
    "#     loss = mse_loss(\n",
    "#         tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "#         tf.reshape(outputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "#     )\n",
    "#     return loss\n",
    "\n",
    "def make_mse_per_sample(inputs, outputs):\n",
    "    outputs = tf.cast(outputs, dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "\n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = outputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = outputs[:, :, 3]\n",
    "\n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = outputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        outputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        outputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "    outputs = mask * outputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (nmet + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(outputs, [-1, (nmet + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def make_mse(inputs, outputs):\n",
    "    loss = make_mse_per_sample(inputs, outputs)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def scale_pt(X, pt_scaler=None):\n",
    "    pt = X[:, 0::nfeat]\n",
    "    if pt_scaler is None:\n",
    "        pt_scaler = StandardScaler()\n",
    "        pt_scaled = pt_scaler.fit_transform(pt)\n",
    "    else:\n",
    "        pt_scaled = pt_scaler.transform(pt)\n",
    "    X_scaled = np.copy(X)\n",
    "    X_scaled[:, 0::nfeat] = np.multiply(pt_scaled, pt != 0)\n",
    "    return X_scaled, pt_scaler\n",
    "\n",
    "def plot_ROC(method, fpr, tpr, tpr_1em5):\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f\"{method}, AUC={auc(fpr, tpr)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr[tpr_1em5]*100:.3f}%\",\n",
    "    )\n",
    "\n",
    "def plot_ROC(method, fpr, tpr, tpr_1em5, n_comp):\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        label=f\"{method}-{n_comp}, AUC={auc(fpr, tpr)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr[tpr_1em5]*100:.3f}%\",\n",
    "    )\n",
    "\n",
    "def get_loss_pumap(X_scaled,inv_transform_data):\n",
    "    #Extract loss from model predictions using make_mse_per_sample function analyzed above\n",
    "    return np.array(make_mse_per_sample(X_scaled, inv_transform_data))\n",
    "\n",
    "def get_loss_pca(X_scaled,inv_transform_data):\n",
    "    #Extract loss from model predictions using make_mse_per_sample function analyzed above\n",
    "    return np.array(make_mse_per_sample(X_scaled, inv_transform_data))\n",
    "\n",
    "def make_mse_per_sample_ae_class(inputs, outputs):\n",
    "    outputs = tf.cast(outputs, dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "\n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    outputs = tf.reshape(outputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = outputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = outputs[:, :, 3]\n",
    "\n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(outputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = outputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        outputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(outputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        outputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    outputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=outputs.dtype)\n",
    "    outputs = mask * outputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(outputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def make_mse_ae(inputs, outputs):\n",
    "    loss = make_mse_per_sample_ae_class(inputs, outputs)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_loss_ae(X, X_scaled):\n",
    "    return np.array(make_mse_per_sample_ae_class(X_scaled, model.predict(X, batch_size=1024)))\n",
    "\n",
    "def make_mse_per_sample_vae_class(inputs, outputs, latent_dimension):\n",
    "    mainOutputs = tf.cast(outputs[:, latent_dimension:-latent_dimension], dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "    meanLatentSpaceVector = outputs[:, :latent_dimension]\n",
    "    logVarVector = outputs[:, -latent_dimension:]\n",
    "    beta = 0.5\n",
    "    klDivCoef = (beta) * -0.5\n",
    "    \n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    mainOutputs = tf.reshape(mainOutputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = mainOutputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = mainOutputs[:, :, 3]\n",
    "    \n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(mainOutputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = mainOutputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(mainOutputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    mainOutputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=mainOutputs.dtype)\n",
    "    mainOutputs = mask * mainOutputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    mse_loss_value = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(mainOutputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    mse_loss_value = tf.math.reduce_mean(mse_loss_value, axis=0)\n",
    "    \n",
    "    kl_divergence = tf.math.multiply(klDivCoef, tf.reduce_sum(1 + logVarVector - tf.square(meanLatentSpaceVector) - tf.exp(logVarVector), axis=-1))\n",
    "    kl_divergence = tf.math.reduce_mean(kl_divergence, axis=0)\n",
    "    kl_divergence = tf.cast(kl_divergence, dtype = mse_loss_value.dtype)\n",
    "\n",
    "    # Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = tf.math.add(tf.math.multiply((1 - beta), mse_loss_value), kl_divergence)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def make_mse_vae(inputs, outputs):\n",
    "    global latent_dimension\n",
    "    loss = make_mse_per_sample_vae_class(inputs, outputs, latent_dimension)\n",
    "\n",
    "    #loss = tf.math.reduce_mean(loss, axis=0)  # average over batch\n",
    "    loss = tf.cast(loss, dtype=inputs.dtype)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def mod_make_mse_per_sample_vae_class(inputs, outputs, latent_dimension):\n",
    "    mainOutputs = tf.cast(outputs[:, latent_dimension:-latent_dimension], dtype=inputs.dtype)  # make inputs and outputs same type\n",
    "    meanLatentSpaceVector = outputs[:, :latent_dimension]\n",
    "    logVarVector = outputs[:, -latent_dimension:]\n",
    "    beta = 0.5\n",
    "    klDivCoef = (beta) * -0.5\n",
    "    \n",
    "    #1+4+4+10 = 19 with 3 features of pT, eta, phi which are transverse momentum, pseduorapidity, azimuthal angle\n",
    "    # as in Main AE paper\n",
    "    inputs = tf.reshape(inputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "    mainOutputs = tf.reshape(mainOutputs, [-1, (nmet + nele + nmu + njet), nfeat])\n",
    "\n",
    "    # extract pt\n",
    "    outputs_pt = mainOutputs[:, :, 0]\n",
    "    \n",
    "    # extract class\n",
    "    outputs_class = mainOutputs[:, :, 3]\n",
    "    \n",
    "    # trick with phi (rescaled tanh activation function) - pi times tanh of azimuthal angle\n",
    "    outputs_phi = phi_max * tf.math.tanh(mainOutputs[:, :, 2])\n",
    "\n",
    "    #Extracts missing transverse energy pseudorapidity outputs\n",
    "    outputs_eta_met = mainOutputs[:, 0:1, 1]\n",
    "\n",
    "    # trick with eta (rescaled tanh activation function) - max electron pseudorapidity times tanh of pseudorapidity\n",
    "    outputs_eta_ele = ele_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, ele_off : ele_off + nele, 1]\n",
    "    )\n",
    "\n",
    "    #Treatment of muon pseudorapidity analogous to that of electron\n",
    "    outputs_eta_mu = mu_eta_max * tf.math.tanh(mainOutputs[:, mu_off : mu_off + nmu, 1])\n",
    "\n",
    "    #Treatment of jet pseudorapidity analogous to that of electrons and muons\n",
    "    outputs_eta_jet = jet_eta_max * tf.math.tanh(\n",
    "        mainOutputs[:, jet_off : jet_off + njet, 1]\n",
    "    )\n",
    "\n",
    "    #Output psuedorapidity is triple with missing transverse eneergy, electron, muon, jet\n",
    "    outputs_eta = tf.concat(\n",
    "        [outputs_eta_met, outputs_eta_ele, outputs_eta_mu, outputs_eta_jet], axis=1\n",
    "    )\n",
    "\n",
    "    # use both tricks - stacks into standard triple - transvere momenta, pseudorapidity, azimuthal angle\n",
    "    mainOutputs = tf.stack([outputs_pt, outputs_eta, outputs_phi, outputs_class], axis=-1)\n",
    "\n",
    "    # mask zero features - Zero Padding after output formation\n",
    "    mask = tf.math.not_equal(inputs, 0)\n",
    "    mask = tf.cast(mask, dtype=mainOutputs.dtype)\n",
    "    mainOutputs = mask * mainOutputs\n",
    "\n",
    "    #Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    mse_loss_value = mse_loss(\n",
    "        tf.reshape(inputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "        tf.reshape(mainOutputs, [-1, (1 + nele + nmu + njet) * nfeat]),\n",
    "    )\n",
    "    \n",
    "    #mse_loss_value = tf.math.reduce_mean(mse_loss_value, axis=0)\n",
    "    \n",
    "    kl_divergence = tf.math.multiply(klDivCoef, tf.reduce_sum(1 + logVarVector - tf.square(meanLatentSpaceVector) - tf.exp(logVarVector), axis=-1))\n",
    "    #kl_divergence = tf.math.reduce_mean(kl_divergence, axis=0)\n",
    "    kl_divergence = tf.cast(kl_divergence, dtype = mse_loss_value.dtype)\n",
    "\n",
    "    # Apply previously defined MSE_loss function 1 - corresponding to nmet\n",
    "    loss = tf.math.add(tf.math.multiply((1 - beta), mse_loss_value), kl_divergence)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def get_loss_vae(X, X_scaled, latent_dimension):\n",
    "    return np.array(mod_make_mse_per_sample_vae_class(X_scaled, model.predict(X, batch_size=1024), latent_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6c793a-68c5-4c1e-94c2-484c6a2e21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PUMAP_ROC(signal_data, n_comp):\n",
    "    # Define the model\n",
    "    #, parametric_reconstruction=True, autoencoder_loss=True\n",
    "    model = PUMAP(n_components=n_comp, low_memory=True)\n",
    "    trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    with open(f\"pumap_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    \n",
    "    inv_transform_training_data = model.inverse_transform(trainEmbedding)\n",
    "    \n",
    "    background_loss = get_loss_pumap(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    \n",
    "    print(\"Starting PUMAP signal embedding: \" + signal_label)\n",
    "    inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "    \n",
    "    signal_loss = get_loss_pumap(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "    print(\"Successful PUMAP signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    \n",
    "    # fpr_pumap = fpr\n",
    "    # tpr_pumap = tpr\n",
    "    # tpr_1em5_pumap = tpr_1em5\n",
    "    # auc_pumap = auc\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be5361a-c2fc-427e-8922-8f6306fa8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE_ROC(signal_data, n_comp):\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            min_delta=0.0001,\n",
    "            cooldown=2,\n",
    "            min_lr=1e-6,\n",
    "        ),\n",
    "        TerminateOnNaN(),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", verbose=1, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    inputs = Input(shape=(X_train[:, 1:].shape[1],))\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(n_comp, kernel_initializer=HeUniform())(x)\n",
    "    x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    outputs = Dense(X_train[:, 1:].shape[1], kernel_initializer=HeUniform())(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss=make_mse_ae)\n",
    "    model.fit(\n",
    "        X_train[:, 1:],\n",
    "        X_train_scaled[:, 1:],\n",
    "        epochs=16,\n",
    "        batch_size=1024,\n",
    "        validation_data=(X_val[:, 1:], X_val_scaled[:, 1:]),\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    with open(f\"ae_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    background_loss = get_loss_ae(X_test[:, 1:], X_test_scaled[:, 1:])\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    signal_loss = get_loss_ae(signal_data[:, 1:], signal_data_scaled[:, 1:])\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    \n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    \n",
    "    # fpr_ae = fpr\n",
    "    # tpr_ae = tpr\n",
    "    # tpr_1em5_ae = tpr_1em5\n",
    "    # auc_ae = auc\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421c07ad-9ce3-4458-a633-b61f64645bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 0\n",
    "# Custom sampling layer to generate epsilon and compute z\n",
    "def sampling(args):\n",
    "    mean, log_var = args\n",
    "    epsilon = tf.random.normal(tf.shape(mean), mean=0.0, stddev=1.0)\n",
    "    return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "    \n",
    "def VAE_ROC(signal_data, n_comp):    \n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            min_delta=0.0001,\n",
    "            cooldown=2,\n",
    "            min_lr=1e-6,\n",
    "        ),\n",
    "        TerminateOnNaN(),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", verbose=1, patience=10, restore_best_weights=True\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    inputs = Input(shape=(X_train[:, 1:].shape[1],))\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    #Block 1\n",
    "    x = Dense(32, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #Block 2\n",
    "    x = Dense(16, kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #Block 3\n",
    "    x = Dense(n_comp, kernel_initializer=HeUniform())(x)\n",
    "    meanLatentSpaceVector = Dense(n_comp, activation='linear')(x)\n",
    "    logVarVector = Dense(n_comp, activation='linear')(x)\n",
    "    # epsilon = tf.random.normal(tf.shape(meanLatentSpaceVector), mean=0.0, stddev=1.0)\n",
    "    # z = meanLatentSpaceVector + tf.exp(0.5 * logVarVector) * epsilon\n",
    "    z = Lambda(sampling)([meanLatentSpaceVector, logVarVector])\n",
    "    \n",
    "    intermediate = z\n",
    "    \n",
    "    # Block 4\n",
    "    z = Dense(16, kernel_initializer=HeUniform())(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = LeakyReLU(alpha=0.3)(z)\n",
    "    \n",
    "    # Block 5\n",
    "    z = Dense(32, kernel_initializer=HeUniform())(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = LeakyReLU(alpha=0.3)(z)\n",
    "    \n",
    "    # decoderEpsilon = tf.random.normal(tf.shape(meanLatentSpaceVector), mean=0.0, stddev=1.0)\n",
    "    # decoderZ = meanLatentSpaceVector + tf.exp(0.5 * logVarVector) * decoderEpsilon\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(X_train[:, 1:].shape[1], kernel_initializer=HeUniform())(z)\n",
    "    outputs = Concatenate(axis=1)([meanLatentSpaceVector, outputs, logVarVector])\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    global latent_dimension\n",
    "    latent_dimension = n_comp\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss=make_mse_vae)\n",
    "    model.fit(\n",
    "        X_train[:, 1:],\n",
    "        X_train_scaled[:, 1:],\n",
    "        epochs=10,\n",
    "        batch_size=1024,\n",
    "        validation_data=(X_val[:, 1:], X_val_scaled[:, 1:]),\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    with open(f\"vae_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    background_loss = get_loss_vae(X_test[:, 1:], X_test_scaled[:, 1:], n_comp)\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    signal_loss = get_loss_vae(signal_data[:, 1:], signal_data_scaled[:, 1:], n_comp)\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "    # Remove NaN or infinity values from losses\n",
    "    valid_indices = ~np.isnan(merged_loss) & ~np.isinf(merged_loss)\n",
    "    filtered_labels = merged_labels[valid_indices]\n",
    "    filtered_loss = merged_loss[valid_indices]\n",
    "    \n",
    "    #fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    fpr, tpr, thresholds = roc_curve(filtered_labels, filtered_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    \n",
    "    # fpr_vae = fpr\n",
    "    # tpr_vae = tpr\n",
    "    # tpr_1em5_vae = tpr_1em5\n",
    "    # auc_vae = auc\n",
    "\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2dc618-cd05-47a7-b471-9ff3c0b08cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_ROC(signal_data, n_comp):\n",
    "    model = PCA(n_components=n_comp)\n",
    "    \n",
    "    trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "\n",
    "    #Check existence of pumap_model_{n_comp}.pkl\n",
    "    # Save variables to a file\n",
    "    with open(f\"pca_model_{n_comp}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    \n",
    "    inv_transform_training_data = model.inverse_transform(trainEmbedding)\n",
    "    background_loss = get_loss_pca(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "    \n",
    "    # _ = plt.figure()\n",
    "    signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "    signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "    merged_labels = np.concatenate(\n",
    "        [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "    )\n",
    "    \n",
    "    # print(\"Starting PCA signal embedding: \" + signal_label)\n",
    "    inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "    \n",
    "    signal_loss = get_loss_pca(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "    merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "    \n",
    "    # print(\"Successful PCA signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "    tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "    auc_res = auc(fpr, tpr)\n",
    "    \n",
    "    return (fpr, tpr, tpr_1em5, auc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d4a294-b68d-400f-91c5-d5cf60731497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 0\n",
      "Query: 500000\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(host=\"adc-2021.c7skue2e0u6i.us-east-1.rds.amazonaws.com\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"UM#37tz;80\",\n",
    "                        port=\"5432\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Set the schema to be used\n",
    "cur.execute(\"SET search_path TO l1anomaly\")\n",
    "#WHOLE DATASET LINE\n",
    "#random_background_indices = np.random.choice(13450000, size=13450000, replace=False)\n",
    "random_background_indices = np.random.choice(13450000, 1000000, replace=False)\n",
    "# random_signal_indices = np.random.choice(600000, size=600000, replace=False)\n",
    "# random_background_indices = np.random.choice(1560000, size=1560000, replace=False)\n",
    "random_signal_indices = np.random.choice(690000, size=690000, replace=False)\n",
    "# random_background_indices = np.random.choice(10000, size=10000, replace=False)\n",
    "# random_signal_indices = np.random.choice(10000, size=10000, replace=False)\n",
    "# Convert numpy arrays to comma-separated strings\n",
    "random_background_indices_str = ', '.join(map(str, random_background_indices))\n",
    "random_signal_indices_str = ', '.join(map(str, random_signal_indices))\n",
    "\n",
    "# cur.execute(f\"SELECT * FROM background_for_training WHERE idbackground_for_training IN ({random_background_indices_str})\")\n",
    "# background_data = cur.fetchall()\n",
    "\n",
    "cur.execute(f\"SELECT * FROM hToTauTau_13TeV_PU20_filtered WHERE idhToTauTau_13TeV_PU20_filtered IN ({random_signal_indices_str})\")\n",
    "signal_data = cur.fetchall()\n",
    "\n",
    "# background_data = np.array(background_data, dtype=float)\n",
    "signal_data = np.array(signal_data, dtype=float)\n",
    "\n",
    "# Replace NaN values in background and signal data\n",
    "# background_data = replace_nan_with_median(background_data)\n",
    "signal_data = replace_nan_with_median(signal_data)\n",
    "\n",
    "#Let's try getting the background data in with batching\n",
    "# Fetch background data in batches\n",
    "background_data = fetch_data_in_batches(\n",
    "    cur,\n",
    "    table_name=\"background_for_training\",\n",
    "    id_column=\"idbackground_for_training\",\n",
    "    id_list=random_background_indices,\n",
    "    batch_size=500000  # Adjust batch size as needed\n",
    ")\n",
    "\n",
    "# # Fetch signal data in batches\n",
    "# signal_data = fetch_data_in_batches(\n",
    "#     cur,\n",
    "#     table_name=\"hToTauTau_13TeV_PU20_filtered\",\n",
    "#     id_column=\"idhToTauTau_13TeV_PU20_filtered\",\n",
    "#     id_list=random_signal_indices,\n",
    "#     batch_size=100000\n",
    "# )\n",
    "\n",
    "# Signal label\n",
    "signal_label = \"$h^{{0}} \\\\to \\\\tau\\\\tau$\"\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e535a7-b552-4acc-804a-3b35982bc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamental Constants\n",
    "\n",
    "nfeat = 4\n",
    "nmet = 1\n",
    "nele = 4\n",
    "nmu = 4\n",
    "njet = 10\n",
    "ele_off = 1\n",
    "mu_off = nmet + nele\n",
    "jet_off = nmet + nele + nmu\n",
    "phi_max = np.pi\n",
    "ele_eta_max = 3.0\n",
    "mu_eta_max = 2.1\n",
    "jet_eta_max = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eade1629-1de5-4922-8aa2-1d1c19588583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start with Gaussian\n",
    "# background_data_reduced, extraneous = train_test_split(background_data, test_size = 0.5)\n",
    "\n",
    "\n",
    "X_train_val, X_test = train_test_split(background_data.reshape(background_data.shape[0], -1), test_size=0.2, shuffle=True)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.2, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "merged_data = np.concatenate([X_test, signal_data], axis=0)\n",
    "merged_labels = np.concatenate([np.zeros(X_test.shape[0]), np.ones(signal_data.shape[0])], axis=0)\n",
    "merged_data_trans = scaler.transform(merged_data)\n",
    "merged_loss = np.sum(merged_data_trans ** 2, axis=-1)\n",
    "fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "fpr_gaussian = fpr\n",
    "tpr_gaussian = tpr\n",
    "tpr_1em5_gaussian = tpr_1em5\n",
    "auc_gaussian = auc(fpr, tpr)\n",
    "plt.plot(fpr_gaussian, tpr_gaussian, label=f\"Gaussian, AUC={auc(fpr_gaussian, tpr_gaussian)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_gaussian[tpr_1em5_gaussian]*100:.3f}%\")\n",
    "plt.legend(title = str(signal_label) +\" baseline\")\n",
    "plt.plot([1e-6, 1], [1e-6, 1], 'k--')\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], 'r-.')\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fb2b4d-777b-4203-a41e-6902e13e229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue with PUMAP\n",
    "X_train_scaled, pt_scaler = scale_pt(X_train)\n",
    "\n",
    "X_test_scaled, _ = scale_pt(X_test, pt_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b10665-156a-43e4-8a99-12204e3c285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'umap_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53780/78345\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 3ms/step - loss: 0.1377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78345/78345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 3ms/step - loss: 0.1357\n",
      "Epoch 10/10\n",
      "\u001b[1m36380/78345\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 3ms/step - loss: 0.1357"
     ]
    }
   ],
   "source": [
    "(fpr_pumap_two, tpr_pumap_two, tpr_1em5_pumap_two, auc_pumap_two) = PUMAP_ROC(signal_data, 2)\n",
    "(fpr_pumap_three, tpr_pumap_three, tpr_1em5_pumap_three, auc_pumap_three) = PUMAP_ROC(signal_data, 3)\n",
    "(fpr_pumap_four, tpr_pumap_four, tpr_1em5_pumap_four, auc_pumap_four) = PUMAP_ROC(signal_data, 4)\n",
    "(fpr_pumap_five, tpr_pumap_five, tpr_1em5_pumap_five, auc_pumap_five) = PUMAP_ROC(signal_data, 5)\n",
    "(fpr_pumap_eight, tpr_pumap_eight, tpr_1em5_pumap_eight, auc_pumap_eight) = PUMAP_ROC(signal_data, 8)\n",
    "(fpr_pumap_ten, tpr_pumap_ten, tpr_1em5_pumap_ten, auc_pumap_ten) = PUMAP_ROC(signal_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8bf34-3939-40eb-9448-15982a4ff49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_two, tpr_pumap_two, tpr_1em5_pumap_two, 2)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_three, tpr_pumap_three, tpr_1em5_pumap_three, 3)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_four, tpr_pumap_four, tpr_1em5_pumap_four, 4)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_five, tpr_pumap_five, tpr_1em5_pumap_five, 5)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_eight, tpr_pumap_eight, tpr_1em5_pumap_eight, 8)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_ten, tpr_pumap_ten, tpr_1em5_pumap_ten, 10)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "pumap_roc_buffer = io.BytesIO()\n",
    "plt.savefig(pumap_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "pumap_roc_buffer.seek(0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0005b5-3560-431b-b245-616c93e606d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best PUMAP targets for the ultimate plot\n",
    "auc_pumap_dict = {}\n",
    "tpr_1em5_pumap_dict = {}\n",
    "\n",
    "for i in range(2, 11):\n",
    "    (fpr_pumap_test, tpr_pumap_test, tpr_1em5_pumap_test, auc_pumap_test) = PUMAP_ROC(signal_data, i)\n",
    "    auc_dict[i] = auc_pumap_test\n",
    "    tpr_1em5_dict[i] = tpr_1em5_pumap_test\n",
    "\n",
    "sorted_auc_pumap_dict = dict(sorted(auc_pumap_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_pumap_dict = dict(sorted(tpr_1em5_pumap_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_pumap_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_pumap_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_pumap = max(sorted_auc_pumap_dict, key=sorted_auc_pumap_dict.get)\n",
    "k_prime_pumap = max(sorted_tpr_1em5_pumap_dict, key=sorted_tpr_1em5_pumap_dict.get)\n",
    "\n",
    "print(k_pumap)\n",
    "print(k_prime_pumap)\n",
    "\n",
    "(fpr_pumap_target, tpr_pumap_target, tpr_1em5_pumap_target, auc_pumap_target) = PUMAP_ROC(signal_data, k_pumap)\n",
    "(fpr_pumap_target_two, tpr_pumap_target_two, tpr_1em5_pumap_target_two, auc_pumap_target_two) = PUMAP_ROC(signal_data, k_prime_pumap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa2e0d-5251-4c36-8a66-4e21d8cb910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = PCA(n_components=10)\n",
    "\n",
    "# trainEmbedding = model.fit_transform(X_train_scaled)\n",
    "# inv_transform_training_data = model.inverse_transform(trainEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82335ba-b1dd-40b5-a2f1-f96374eb9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_loss = get_loss_pca(X_train_scaled[:, 1:], inv_transform_training_data[:, 1:])\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# signal_data = signal_data.reshape(signal_data.shape[0], -1)\n",
    "# signal_data_scaled, _ = scale_pt(signal_data, pt_scaler)\n",
    "# merged_labels = np.concatenate(\n",
    "#     [np.zeros(X_train.shape[0]), np.ones(signal_data.shape[0])], axis=0\n",
    "# )\n",
    "\n",
    "# print(\"Starting PCA signal embedding: \" + signal_label)\n",
    "# inv_transform_signal_data = model.inverse_transform(model.transform(signal_data_scaled))\n",
    "\n",
    "# signal_loss = get_loss_pca(signal_data_scaled[:, 1:], inv_transform_signal_data[:, 1:])\n",
    "# merged_loss = np.concatenate([background_loss, signal_loss], axis=0)\n",
    "\n",
    "# print(\"Successful PCA signal embedding, inverse transform, and loss computations: \" + signal_label)\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(merged_labels, merged_loss)\n",
    "# tpr_1em5 = find_nearest(fpr, 1e-5)\n",
    "\n",
    "# fpr_pca = fpr\n",
    "# tpr_pca = tpr\n",
    "# tpr_1em5_pca = tpr_1em5\n",
    "# auc_pca = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcba64b-ac4d-46dd-9d9b-075b30ddbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled, _ = scale_pt(X_val, pt_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaf381-2678-4251-b9bb-cd706fef9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_ae_two, tpr_ae_two, tpr_1em5_ae_two, auc_ae_two) = AE_ROC(signal_data, 2)\n",
    "(fpr_ae_three, tpr_ae_three, tpr_1em5_ae_three, auc_ae_three) = AE_ROC(signal_data, 3)\n",
    "(fpr_ae_four, tpr_ae_four, tpr_1em5_ae_four, auc_ae_four) = AE_ROC(signal_data, 4)\n",
    "(fpr_ae_five, tpr_ae_five, tpr_1em5_ae_five, auc_ae_five) = AE_ROC(signal_data, 5)\n",
    "(fpr_ae_eight, tpr_ae_eight, tpr_1em5_ae_eight, auc_ae_eight) = AE_ROC(signal_data, 8)\n",
    "(fpr_ae_ten, tpr_ae_ten, tpr_1em5_ae_ten, auc_ae_ten) = AE_ROC(signal_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72bdab-88fc-42ef-909b-9e5d9f8df502",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"DNNAE\", fpr_ae_two, tpr_ae_two, tpr_1em5_ae_two, 2)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_three, tpr_ae_three, tpr_1em5_ae_three, 3)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_four, tpr_ae_four, tpr_1em5_ae_four, 4)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_five, tpr_ae_five, tpr_1em5_ae_five, 5)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_eight, tpr_ae_eight, tpr_1em5_ae_eight, 8)\n",
    "plot_ROC(\"DNNAE\", fpr_ae_ten, tpr_ae_ten, tpr_1em5_ae_ten, 10)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "ae_roc_buffer = io.BytesIO()\n",
    "plt.savefig(ae_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "ae_roc_buffer.seek(0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ebd1a-8a22-4130-9ee2-9541caf089e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best AE targets for the ultimate plot\n",
    "auc_ae_dict = {}\n",
    "tpr_1em5_ae_dict = {}\n",
    "\n",
    "for i in range(2, 11):\n",
    "    (fpr_ae_test, tpr_ae_test, tpr_1em5_ae_test, auc_ae_test) = AE_ROC(signal_data, i)\n",
    "    auc_dict[i] = auc_ae_test\n",
    "    tpr_1em5_dict[i] = tpr_1em5_ae_test\n",
    "\n",
    "sorted_auc_ae_dict = dict(sorted(auc_ae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_ae_dict = dict(sorted(tpr_1em5_ae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_ae_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_ae_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_ae = max(sorted_auc_ae_dict, key=sorted_auc_ae_dict.get)\n",
    "k_prime_ae = max(sorted_tpr_1em5_ae_dict, key=sorted_tpr_1em5_ae_dict.get)\n",
    "\n",
    "print(k_ae)\n",
    "print(k_prime_ae)\n",
    "\n",
    "(fpr_ae_target, tpr_ae_target, tpr_1em5_ae_target, auc_ae_target) = AE_ROC(signal_data, k_ae)\n",
    "(fpr_ae_target_two, tpr_ae_target_two, tpr_1em5_ae_target_two, auc_ae_target_two) = AE_ROC(signal_data, k_prime_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d0967-c639-496f-add2-a0bcd6ccb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE Stuff starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629640dd-70e5-464a-a2b1-34805f92d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_vae_two, tpr_vae_two, tpr_1em5_vae_two, auc_vae_two) = VAE_ROC(signal_data, 2)\n",
    "(fpr_vae_three, tpr_vae_three, tpr_1em5_vae_three, auc_vae_three) = VAE_ROC(signal_data, 3)\n",
    "(fpr_vae_four, tpr_vae_four, tpr_1em5_vae_four, auc_vae_four) = VAE_ROC(signal_data, 4)\n",
    "(fpr_vae_five, tpr_vae_five, tpr_1em5_vae_five, auc_vae_five) = VAE_ROC(signal_data, 5)\n",
    "(fpr_vae_eight, tpr_vae_eight, tpr_1em5_vae_eight, auc_vae_eight) = VAE_ROC(signal_data, 8)\n",
    "(fpr_vae_ten, tpr_vae_ten, tpr_1em5_vae_ten, auc_vae_ten) = VAE_ROC(signal_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a3f03-e17f-4ce2-92b8-9936445eb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_two, tpr_vae_two, tpr_1em5_vae_two, 2)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_three, tpr_vae_three, tpr_1em5_vae_three, 3)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_four, tpr_vae_four, tpr_1em5_vae_four, 4)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_five, tpr_vae_five, tpr_1em5_vae_five, 5)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_eight, tpr_vae_eight, tpr_1em5_vae_eight, 8)\n",
    "plot_ROC(\"DNNVAE\", fpr_vae_ten, tpr_vae_ten, tpr_1em5_vae_ten, 10)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "vae_roc_buffer = io.BytesIO()\n",
    "plt.savefig(vae_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "vae_roc_buffer.seek(0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f50a7-cc2e-43ad-b24e-d60ba4c6a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best VAE targets for the ultimate plot\n",
    "auc_vae_dict = {}\n",
    "tpr_1em5_vae_dict = {}\n",
    "\n",
    "for i in range(2, 11):\n",
    "    (fpr_vae_test, tpr_vae_test, tpr_1em5_vae_test, auc_vae_test) = VAE_ROC(signal_data, i)\n",
    "    auc_dict[i] = auc_vae_test\n",
    "    tpr_1em5_dict[i] = tpr_1em5_vae_test\n",
    "\n",
    "sorted_auc_vae_dict = dict(sorted(auc_vae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_vae_dict = dict(sorted(tpr_1em5_vae_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_vae_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_vae_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_vae = max(sorted_auc_vae_dict, key=sorted_auc_vae_dict.get)\n",
    "k_prime_vae = max(sorted_tpr_1em5_vae_dict, key=sorted_tpr_1em5_vae_dict.get)\n",
    "\n",
    "print(k_vae)\n",
    "print(k_prime_vae)\n",
    "\n",
    "(fpr_vae_target, tpr_vae_target, tpr_1em5_vae_target, auc_vae_target) = VAE_ROC(signal_data, k_vae)\n",
    "(fpr_vae_target_two, tpr_vae_target_two, tpr_1em5_vae_target_two, auc_vae_target_two) = VAE_ROC(signal_data, k_prime_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34234e7e-16b7-4704-bbf4-bd4d84886769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check background_loss\n",
    "# print(\"Background Loss: \", np.any(np.isnan(background_loss)), np.any(np.isinf(background_loss)), np.max(background_loss))\n",
    "\n",
    "# # Check signal_loss\n",
    "# print(\"Signal Loss: \", np.any(np.isnan(signal_loss)), np.any(np.isinf(signal_loss)), np.max(signal_loss))\n",
    "\n",
    "# # Check merged_loss\n",
    "# print(\"Merged Loss: \", np.any(np.isnan(merged_loss)), np.any(np.isinf(merged_loss)), np.max(merged_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba15f76-48b9-484e-aea0-07d5ab76cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(fpr_gaussian,\n",
    "#          tpr_gaussian,\n",
    "#          label=f\"Gaussian, AUC={auc(fpr_gaussian, tpr_gaussian)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_gaussian[tpr_1em5_gaussian]*100:.3f}%\")\n",
    "\n",
    "# plt.plot(\n",
    "#     fpr_pumap,\n",
    "#     tpr_pumap,\n",
    "#     label=f\"PUMAP, AUC={auc(fpr_pumap, tpr_pumap)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pumap[tpr_1em5_pumap]*100:.3f}%\",\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     fpr_pca,\n",
    "#     tpr_pca,\n",
    "#     label=f\"PCA-10, AUC={auc(fpr_pca, tpr_pca)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_pca[tpr_1em5_pca]*100:.3f}%\",\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     fpr_ae,\n",
    "#     tpr_ae,\n",
    "#     label=f\"DNNAE, AUC={auc(fpr_ae, tpr_ae)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_ae[tpr_1em5_ae]*100:.3f}%\",\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     fpr_vae,\n",
    "#     tpr_vae,\n",
    "#     label=f\"DNNVAE, AUC={auc(fpr_vae, tpr_vae)*100:.2f}%, TPR@FPR $10^{{-5}}$={tpr_vae[tpr_1em5_vae]*100:.3f}%\",\n",
    "# )\n",
    "\n",
    "# plt.legend(title=f\"{signal_label} Baseline\")\n",
    "# plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "# plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "# plt.xlim([1e-6, 1])\n",
    "# plt.ylim([1e-6, 1])\n",
    "# plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a76a75-cd3e-4fb0-8110-7b6c2cd49882",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, auc_pca_two) = PCA_ROC(signal_data, 2)\n",
    "(fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, auc_pca_three) = PCA_ROC(signal_data, 3)\n",
    "(fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, auc_pca_four) = PCA_ROC(signal_data, 4)\n",
    "(fpr_pca_five, tpr_pca_five, tpr_1em5_pca_five, auc_pca_five) = PCA_ROC(signal_data, 5)\n",
    "(fpr_pca_eight, tpr_pca_eight, tpr_1em5_pca_eight, auc_pca_eight) = PCA_ROC(signal_data, 8)\n",
    "(fpr_pca_ten, tpr_pca_ten, tpr_1em5_pca_ten, auc_pca_ten) = PCA_ROC(signal_data, 10)\n",
    "(fpr_pca_twelve, tpr_pca_twelve, tpr_1em5_pca_twelve, auc_pca_twelve) = PCA_ROC(signal_data, 12)\n",
    "(fpr_pca_thirteen, tpr_pca_thirteen, tpr_1em5_pca_thirteen, auc_pca_thirteen) = PCA_ROC(signal_data, 13)\n",
    "(fpr_pca_sixteen, tpr_pca_sixteen, tpr_1em5_pca_sixteen, auc_pca_sixteen) = PCA_ROC(signal_data, 16)\n",
    "(fpr_pca_thirtytwo, tpr_pca_thirtytwo, tpr_1em5_pca_thirtytwo, auc_pca_thirtytwo) = PCA_ROC(signal_data, 32)\n",
    "(fpr_pca_sixtyfour, tpr_pca_sixtyfour, tpr_1em5_pca_sixtyfour, auc_pca_sixtyfour) = PCA_ROC(signal_data, 64)\n",
    "(fpr_pca_seventy, tpr_pca_seventy, tpr_1em5_pca_seventy, auc_pca_seventy) = PCA_ROC(signal_data, 70)\n",
    "(fpr_pca_seventysix, tpr_pca_seventysix, tpr_1em5_pca_seventysix, auc_pca_seventysix) = PCA_ROC(signal_data, 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e6e04-9555-4f4a-9862-9446c4a97381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc_dict = {}\n",
    "# tpr_1em5_dict = {}\n",
    "\n",
    "# for i in range(2, 77):\n",
    "#     (fpr_pca_test, tpr_pca_test, tpr_1em5_pca_test, auc_pca_test) = PCA_ROC(signal_data, i)\n",
    "#     auc_dict[i] = auc_pca_test\n",
    "#     tpr_1em5_dict[i] = tpr_1em5_pca_test\n",
    "\n",
    "# sorted_dict_auc = dict(sorted(auc_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# sorted_dict_tpr_1em5 = dict(sorted(tpr_1em5_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# # Print header\n",
    "# print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "# print(\"-\" * 25)\n",
    "\n",
    "# # Print each row\n",
    "# for n_components, auc in sorted_dict_auc.items():\n",
    "#     tpr_1em5 = sorted_dict_tpr_1em5[n_components]\n",
    "#     print(f\"{n_components:<15} {auc*100:.2f}% {tpr_1em5*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9cd8d-e32d-4d03-9ff3-cfa6c82ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Add data for plotting\n",
    "plot_ROC(\"PCA\", fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, 2)\n",
    "plot_ROC(\"PCA\", fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, 3)\n",
    "plot_ROC(\"PCA\", fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, 4)\n",
    "plot_ROC(\"PCA\", fpr_pca_five, tpr_pca_five, tpr_1em5_pca_five, 5)\n",
    "plot_ROC(\"PCA\", fpr_pca_eight, tpr_pca_eight, tpr_1em5_pca_eight, 8)\n",
    "plot_ROC(\"PCA\", fpr_pca_ten, tpr_pca_ten, tpr_1em5_pca_ten, 10)\n",
    "plot_ROC(\"PCA\", fpr_pca_twelve, tpr_pca_twelve, tpr_1em5_pca_twelve, 12)\n",
    "plot_ROC(\"PCA\", fpr_pca_thirteen, tpr_pca_thirteen, tpr_1em5_pca_thirteen, 13)\n",
    "plot_ROC(\"PCA\", fpr_pca_sixteen, tpr_pca_sixteen, tpr_1em5_pca_sixteen, 16)\n",
    "plot_ROC(\"PCA\", fpr_pca_thirtytwo, tpr_pca_thirtytwo, tpr_1em5_pca_thirtytwo, 32)\n",
    "plot_ROC(\"PCA\", fpr_pca_sixtyfour, tpr_pca_sixtyfour, tpr_1em5_pca_sixtyfour, 64)\n",
    "plot_ROC(\"PCA\", fpr_pca_seventy, tpr_pca_seventy, tpr_1em5_pca_seventy, 70)\n",
    "plot_ROC(\"PCA\", fpr_pca_seventysix, tpr_pca_seventysix, tpr_1em5_pca_seventysix, 76)\n",
    "\n",
    "# Add lines and set axes limits\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Add legend to the plot\n",
    "legend = plt.legend(\n",
    "    title=f\"{signal_label} Baseline\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0\n",
    ")\n",
    "\n",
    "#Save the plot in a buffer\n",
    "pca_roc_buffer = io.BytesIO()\n",
    "plt.savefig(pca_roc_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "pca_roc_buffer.seek(0)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Save the main plot without the legend\n",
    "# file_head = \"/tmp/\"\n",
    "# pca_roc_file_name = file_head + f\"New-PCA-ROC-Curve-B{random_background_indices.size}-S{random_signal_indices.size}\"\n",
    "# plt.savefig(f\"{pca_roc_file_name}.png\", format='png', dpi=300, bbox_inches='tight')\n",
    "# plt.close()\n",
    "# Save the main plot with buffer\n",
    "\n",
    "# Create a separate figure for the legend\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))  # Adjust the figure size\n",
    "# legend_fig = ax.legend_ = legend  # Use the existing legend\n",
    "# ax.axis(\"off\")  # Turn off axes for the legend figure\n",
    "\n",
    "# # Save the legend as a separate image\n",
    "# legend_file_name = f\"{roc_file_name}_legend.png\"\n",
    "# fig.savefig(legend_file_name, format='png', dpi=300, bbox_inches='tight')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3036e36-073c-4e93-84a5-d8dd87d98ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best PCA targets for the ultimate plot\n",
    "auc_pca_dict = {}\n",
    "tpr_1em5_pca_dict = {}\n",
    "\n",
    "for i in range(2, 77):\n",
    "    (fpr_pca_test, tpr_pca_test, tpr_1em5_pca_test, auc_pca_test) = VAE_ROC(signal_data, i)\n",
    "    auc_dict[i] = auc_pca_test\n",
    "    tpr_1em5_dict[i] = tpr_1em5_pca_test\n",
    "\n",
    "sorted_auc_pca_dict = dict(sorted(auc_pca_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_tpr_1em5_pca_dict = dict(sorted(tpr_1em5_pca_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print header\n",
    "print(f\"{'PCA Components':<15} {'AUC (%)':<10} {'TPR@FPR 10^{-5} (%)':<10}\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print each row\n",
    "for n_components, auc_val in sorted_auc_pca_dict.items():\n",
    "    tpr_1em5 = sorted_tpr_1em5_pca_dict[n_components]\n",
    "    print(f\"{n_components:<15} {auc_val*100:.2f}% {tpr_1em5*100:.3f}%\")\n",
    "\t\n",
    "k_pca = max(sorted_auc_pca_dict, key=sorted_auc_pca_dict.get)\n",
    "k_prime_pca = max(sorted_tpr_1em5_pca_dict, key=sorted_tpr_1em5_pca_dict.get)\n",
    "\n",
    "print(k_pca)\n",
    "print(k_prime_pca)\n",
    "\n",
    "(fpr_pca_target, tpr_pca_target, tpr_1em5_pca_target, auc_pca_target) = PCA_ROC(signal_data, k_pca)\n",
    "(fpr_pca_target_two, tpr_pca_target_two, tpr_1em5_pca_target_two, auc_pca_target_two) = PCA_ROC(signal_data, k_prime_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ce434-697b-4961-9d70-8bf742cc57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian\n",
    "plot_ROC(\"Gaussian\", fpr_gaussian, tpr_gaussian, tpr_1em5_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34defdf1-1a8e-421e-b115-b70418e4040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get PUMAP-2, PUMAP-3, PUMAP-4, PUMAP with max AUC, PUMAP with max TPR@FPR 10^-5\n",
    "\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_two, tpr_pumap_two, tpr_1em5_pumap_two, 2)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_three, tpr_pumap_three, tpr_1em5_pumap_three, 3)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_four, tpr_pumap_four, tpr_1em5_pumap_four, 4)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_target, tpr_pumap_target, tpr_1em5_pumap_target, k_pumap)\n",
    "plot_ROC(\"PUMAP\", fpr_pumap_target_two, tpr_pumap_target_two, tpr_1em5_pumap_target_two, k_prime_pumap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28908143-8403-4c7b-81c1-c4b7a3caf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AE-2, AE-3, AE-4, AE with max AUC, AE with max TPR@FPR 10^-5\n",
    "\n",
    "plot_ROC(\"AE\", fpr_ae_two, tpr_ae_two, tpr_1em5_ae_two, 2)\n",
    "plot_ROC(\"AE\", fpr_ae_three, tpr_ae_three, tpr_1em5_ae_three, 3)\n",
    "plot_ROC(\"AE\", fpr_ae_four, tpr_ae_four, tpr_1em5_ae_four, 4)\n",
    "plot_ROC(\"AE\", fpr_ae_target, tpr_ae_target, tpr_1em5_ae_target, k_ae)\n",
    "plot_ROC(\"AE\", fpr_ae_target_two, tpr_ae_target_two, tpr_1em5_ae_target_two, k_prime_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f515295-35fe-4e44-97d6-5fd4807c7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get VAE-2, VAE-3, VAE-4, VAE with max AUC, VAE with max TPR@FPR 10^-5\n",
    "\n",
    "plot_ROC(\"VAE\", fpr_vae_two, tpr_vae_two, tpr_1em5_vae_two, 2)\n",
    "plot_ROC(\"VAE\", fpr_vae_three, tpr_vae_three, tpr_1em5_vae_three, 3)\n",
    "plot_ROC(\"VAE\", fpr_vae_four, tpr_vae_four, tpr_1em5_vae_four, 4)\n",
    "plot_ROC(\"VAE\", fpr_vae_target, tpr_vae_target, tpr_1em5_vae_target, k_vae)\n",
    "plot_ROC(\"VAE\", fpr_vae_target_two, tpr_vae_target_two, tpr_1em5_vae_target_two, k_prime_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb2987-6ea4-4898-9878-d8f00a5342d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get PCA-2, PCA-3, PCA-4, PCA with max AUC, PCA with max TPR@FPR 10^-5\n",
    "plot_ROC(\"PCA\", fpr_pca_two, tpr_pca_two, tpr_1em5_pca_two, 2)\n",
    "plot_ROC(\"PCA\", fpr_pca_three, tpr_pca_three, tpr_1em5_pca_three, 3)\n",
    "plot_ROC(\"PCA\", fpr_pca_four, tpr_pca_four, tpr_1em5_pca_four, 4)\n",
    "plot_ROC(\"PCA\", fpr_pca_target, tpr_pca_target, tpr_1em5_pca_target, k_pca)\n",
    "plot_ROC(\"PCA\", fpr_pca_target_two, tpr_pca_target_two, tpr_1em5_pca_target_two, k_prime_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fa7d2-2ae1-4eda-8fdd-e249ed730399",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(title=f\"{signal_label} Baseline\")\n",
    "plt.plot([1e-6, 1], [1e-6, 1], \"k--\")\n",
    "plt.plot([1e-5, 1e-5], [1e-6, 1], \"r-.\")\n",
    "plt.xlim([1e-6, 1])\n",
    "plt.ylim([1e-6, 1])\n",
    "plt.loglog()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "roc_file_name = file_head + f\"New-ROC-Curve-B{random_background_indices.size}-S{random_signal_indices.size}\"\n",
    "plt.savefig(f\"{roc_file_name}.png\", format='png', dpi=300)  # High resolution\n",
    "# Save the plot using buffer\n",
    "roc_buffer = io.BytesIO()\n",
    "plt.savefig(roc_buffer, format='png', dpi=300)  # High resolution\n",
    "roc_buffer.seek(0)\n",
    "plt.close()  # Close the figure to release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdafbc5-4bee-4b41-859a-028ba212b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "# from pathlib import Path\n",
    "\n",
    "# Email details\n",
    "sender_email = \"rosachdeva@ucsd.edu\"\n",
    "# receiver_email = \"rosachdeva@ucsd.edu\"\n",
    "receiver_emails = [\"rosachdeva@ucsd.edu\", \"mquinnan@ucsd.edu\"]  # List of recipients\n",
    "password = \"uuvo esud bmib fvvk\"  # Use app-specific password if using Gmail\n",
    "\n",
    "# Create the email message\n",
    "msg = EmailMessage()\n",
    "msg['Subject'] = 'Final ROC Curve Results'\n",
    "msg['From'] = sender_email\n",
    "#msg['To'] = receiver_email\n",
    "msg['To'] = \", \".join(receiver_emails)  # Join multiple emails into a string\n",
    "\n",
    "\n",
    "# Attach text content\n",
    "msg.set_content(\"Please find the final ROC curve attached.\")\n",
    "\n",
    "# Add the ROC curve image\n",
    "msg.add_attachment(roc_buffer.read(), maintype='image', subtype='png', filename=\"roc_curve.png\")\n",
    "msg.add_attachment(pumap_roc_buffer.read(), maintype='image', subtype='png', filename=\"pumap_roc_curve.png\")\n",
    "msg.add_attachment(ae_roc_buffer.read(), maintype='image', subtype='png', filename=\"ae_roc_curve.png\")\n",
    "msg.add_attachment(vae_roc_buffer.read(), maintype='image', subtype='png', filename=\"vae_roc_curve.png\")\n",
    "msg.add_attachment(pca_roc_buffer.read(), maintype='image', subtype='png', filename=\"pca_roc_curve.png\")\n",
    "# roc_curve_path = file_head + roc_file_name + \".png\"  # Path to the ROC curve image\n",
    "# pca_roc_curve_path = file_head + pca_roc_file_name + \".png\"  # Path to the PCA ROC curve image\n",
    "# if Path(roc_curve_path).exists():\n",
    "#    with open(roc_curve_path, 'rb') as img:\n",
    "#        img_data = img.read()\n",
    "#        msg.add_attachment(img_data, maintype='image', subtype='png', filename=\"roc_curve.png\")\n",
    "# else:\n",
    "#    print(f\"Error: {roc_curve_path} not found. Ensure the ROC curve image is saved.\")\n",
    "\n",
    "# if Path(pca_roc_curve_path).exists():\n",
    "#    with open(pca_roc_curve_path, 'rb') as img:\n",
    "#        img_data = img.read()\n",
    "#        msg.add_attachment(img_data, maintype='image', subtype='png', filename=\"pca_roc_curve.png\")\n",
    "# else:\n",
    "#    print(f\"Error: {roc_curve_path} not found. Ensure the ROC curve image is saved.\")\n",
    "\n",
    "\n",
    "\n",
    "# Send the email\n",
    "try:\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:  # For Gmail. Use other SMTP servers if needed.\n",
    "        server.login(sender_email, password)\n",
    "        server.send_message(msg)\n",
    "    print(\"Email sent successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error sending email: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15fe26-afcb-40c3-94ea-0761b786d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for Gaussian ROC Curve\n",
    "gaussian_roc_variables = {\n",
    "    'fpr_gaussian': fpr_gaussian,\n",
    "    'tpr_gaussian': tpr_gaussian,\n",
    "    'tpr_1em5_gaussian': tpr_1em5_gaussian,\n",
    "    'auc_gaussian': auc_gaussian\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "gaussian_roc_file = \"gaussian_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(gaussian_roc_file, 'wb') as file:\n",
    "    pickle.dump(gaussian_roc_variables, file)\n",
    "\n",
    "print(f\"Gaussian ROC variables saved to {gaussian_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0521554-e0f0-4703-b030-7a282433d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for PUMAP ROC curve\n",
    "pumap_roc_variables = {\n",
    "    'fpr_pumap_two': fpr_pumap_two,\n",
    "    'tpr_pumap_two': tpr_pumap_two,\n",
    "    'tpr_1em5_pumap_two': tpr_1em5_pumap_two,\n",
    "    'auc_pumap_two': auc_pumap_two,\n",
    "    'fpr_pumap_three': fpr_pumap_three,\n",
    "    'tpr_pumap_three': tpr_pumap_three,\n",
    "    'tpr_1em5_pumap_three': tpr_1em5_pumap_three,\n",
    "    'auc_pumap_three': auc_pumap_three,\n",
    "    'fpr_pumap_four': fpr_pumap_four,\n",
    "    'tpr_pumap_four': tpr_pumap_four,\n",
    "    'tpr_1em5_pumap_four': tpr_1em5_pumap_four,\n",
    "    'auc_pumap_four': auc_pumap_four,\n",
    "    'fpr_pumap_five': fpr_pumap_five,\n",
    "    'tpr_pumap_five': tpr_pumap_five,\n",
    "    'tpr_1em5_pumap_five': tpr_1em5_pumap_five,\n",
    "    'auc_pumap_five': auc_pumap_five,\n",
    "    'fpr_pumap_eight': fpr_pumap_eight,\n",
    "    'tpr_pumap_eight': tpr_pumap_eight,\n",
    "    'tpr_1em5_pumap_eight': tpr_1em5_pumap_eight,\n",
    "    'auc_pumap_eight': auc_pumap_eight,\n",
    "    'fpr_pumap_ten': fpr_pumap_ten,\n",
    "    'tpr_pumap_ten': tpr_pumap_ten,\n",
    "    'tpr_1em5_pumap_ten': tpr_1em5_pumap_ten,\n",
    "    'auc_pumap_ten': auc_pumap_ten,\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "pumap_roc_file = \"pumap_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(pumap_roc_file, 'wb') as file:\n",
    "    pickle.dump(pumap_roc_variables, file)\n",
    "\n",
    "print(f\"PUMAP ROC variables saved to {pumap_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ca723-5fd1-426e-9312-a04f879e1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for DNNAE ROC curve\n",
    "ae_roc_variables = {\n",
    "    'fpr_ae_two': fpr_ae_two,\n",
    "    'tpr_ae_two': tpr_ae_two,\n",
    "    'tpr_1em5_ae_two': tpr_1em5_ae_two,\n",
    "    'auc_ae_two': auc_ae_two,\n",
    "    'fpr_ae_three': fpr_ae_three,\n",
    "    'tpr_ae_three': tpr_ae_three,\n",
    "    'tpr_1em5_ae_three': tpr_1em5_ae_three,\n",
    "    'auc_ae_three': auc_ae_three,\n",
    "    'fpr_ae_four': fpr_ae_four,\n",
    "    'tpr_ae_four': tpr_ae_four,\n",
    "    'tpr_1em5_ae_four': tpr_1em5_ae_four,\n",
    "    'auc_ae_four': auc_ae_four,\n",
    "    'fpr_ae_five': fpr_ae_five,\n",
    "    'tpr_ae_five': tpr_ae_five,\n",
    "    'tpr_1em5_ae_five': tpr_1em5_ae_five,\n",
    "    'auc_ae_five': auc_ae_five,\n",
    "    'fpr_ae_eight': fpr_ae_eight,\n",
    "    'tpr_ae_eight': tpr_ae_eight,\n",
    "    'tpr_1em5_ae_eight': tpr_1em5_ae_eight,\n",
    "    'auc_ae_eight': auc_ae_eight,\n",
    "    'fpr_ae_ten': fpr_ae_ten,\n",
    "    'tpr_ae_ten': tpr_ae_ten,\n",
    "    'tpr_1em5_ae_ten': tpr_1em5_ae_ten,\n",
    "    'auc_ae_ten': auc_ae_ten,\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "ae_roc_file = \"ae_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(ae_roc_file, 'wb') as file:\n",
    "    pickle.dump(ae_roc_variables, file)\n",
    "\n",
    "print(f\"DNNAE ROC variables saved to {ae_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdc771-db7d-4fef-b83b-37857771ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for DNNVAE ROC curve\n",
    "vae_roc_variables = {\n",
    "    'fpr_vae_two': fpr_vae_two,\n",
    "    'tpr_vae_two': tpr_vae_two,\n",
    "    'tpr_1em5_vae_two': tpr_1em5_vae_two,\n",
    "    'auc_vae_two': auc_vae_two,\n",
    "    'fpr_vae_three': fpr_vae_three,\n",
    "    'tpr_vae_three': tpr_vae_three,\n",
    "    'tpr_1em5_vae_three': tpr_1em5_vae_three,\n",
    "    'auc_vae_three': auc_vae_three,\n",
    "    'fpr_vae_four': fpr_vae_four,\n",
    "    'tpr_vae_four': tpr_vae_four,\n",
    "    'tpr_1em5_vae_four': tpr_1em5_vae_four,\n",
    "    'auc_vae_four': auc_vae_four,\n",
    "    'fpr_vae_five': fpr_vae_five,\n",
    "    'tpr_vae_five': tpr_vae_five,\n",
    "    'tpr_1em5_vae_five': tpr_1em5_vae_five,\n",
    "    'auc_vae_five': auc_vae_five,\n",
    "    'fpr_vae_eight': fpr_vae_eight,\n",
    "    'tpr_vae_eight': tpr_vae_eight,\n",
    "    'tpr_1em5_vae_eight': tpr_1em5_vae_eight,\n",
    "    'auc_vae_eight': auc_vae_eight,\n",
    "    'fpr_vae_ten': fpr_vae_ten,\n",
    "    'tpr_vae_ten': tpr_vae_ten,\n",
    "    'tpr_1em5_vae_ten': tpr_1em5_vae_ten,\n",
    "    'auc_vae_ten': auc_vae_ten,\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "vae_roc_file = \"vae_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(vae_roc_file, 'wb') as file:\n",
    "    pickle.dump(vae_roc_variables, file)\n",
    "\n",
    "print(f\"DNNVAE ROC variables saved to {vae_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c13bc6-3fad-484a-b509-342e96efea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for PCA ROC curve\n",
    "pca_roc_variables = {\n",
    "    'fpr_pca_two': fpr_pca_two,\n",
    "    'tpr_pca_two': tpr_pca_two,\n",
    "    'tpr_1em5_pca_two': tpr_1em5_pca_two,\n",
    "    'auc_pca_two': auc_pca_two,\n",
    "    'fpr_pca_three': fpr_pca_three,\n",
    "    'tpr_pca_three': tpr_pca_three,\n",
    "    'tpr_1em5_pca_three': tpr_1em5_pca_three,\n",
    "    'auc_pca_three': auc_pca_three,\n",
    "    'fpr_pca_four': fpr_pca_four,\n",
    "    'tpr_pca_four': tpr_pca_four,\n",
    "    'tpr_1em5_pca_four': tpr_1em5_pca_four,\n",
    "    'auc_pca_four': auc_pca_four,\n",
    "    'fpr_pca_five': fpr_pca_five,\n",
    "    'tpr_pca_five': tpr_pca_five,\n",
    "    'tpr_1em5_pca_five': tpr_1em5_pca_five,\n",
    "    'auc_pca_five': auc_pca_five,\n",
    "    'fpr_pca_eight': fpr_pca_eight,\n",
    "    'tpr_pca_eight': tpr_pca_eight,\n",
    "    'tpr_1em5_pca_eight': tpr_1em5_pca_eight,\n",
    "    'auc_pca_eight': auc_pca_eight,\n",
    "    'fpr_pca_ten': fpr_pca_ten,\n",
    "    'tpr_pca_ten': tpr_pca_ten,\n",
    "    'tpr_1em5_pca_ten': tpr_1em5_pca_ten,\n",
    "    'auc_pca_ten': auc_pca_ten,\n",
    "    'fpr_pca_twelve': fpr_pca_twelve,\n",
    "    'tpr_pca_twelve': tpr_pca_twelve,\n",
    "    'tpr_1em5_pca_twelve': tpr_1em5_pca_twelve,\n",
    "    'auc_pca_twelve': auc_pca_twelve,\n",
    "    'fpr_pca_thirteen': fpr_pca_thirteen,\n",
    "    'tpr_pca_thirteen': tpr_pca_thirteen,\n",
    "    'tpr_1em5_pca_thirteen': tpr_1em5_pca_thirteen,\n",
    "    'auc_pca_thirteen': auc_pca_thirteen,\n",
    "    'fpr_pca_sixteen': fpr_pca_sixteen,\n",
    "    'tpr_pca_sixteen': tpr_pca_sixteen,\n",
    "    'tpr_1em5_pca_sixteen': tpr_1em5_pca_sixteen,\n",
    "    'auc_pca_sixteen': auc_pca_sixteen,\n",
    "    'fpr_pca_thirtytwo': fpr_pca_thirtytwo,\n",
    "    'tpr_pca_thirtytwo': tpr_pca_thirtytwo,\n",
    "    'tpr_1em5_pca_thirtytwo': tpr_1em5_pca_thirtytwo,\n",
    "    'auc_pca_thirtytwo': auc_pca_thirtytwo,\n",
    "    'fpr_pca_sixtyfour': fpr_pca_sixtyfour,\n",
    "    'tpr_pca_sixtyfour': tpr_pca_sixtyfour,\n",
    "    'tpr_1em5_pca_sixtyfour': tpr_1em5_pca_sixtyfour,\n",
    "    'auc_pca_sixtyfour': auc_pca_sixtyfour,\n",
    "    'fpr_pca_seventy': fpr_pca_seventy,\n",
    "    'tpr_pca_seventy': tpr_pca_seventy,\n",
    "    'tpr_1em5_pca_seventy': tpr_1em5_pca_seventy,\n",
    "    'auc_pca_seventy': auc_pca_seventy,\n",
    "    'fpr_pca_seventysix': fpr_pca_seventysix,\n",
    "    'tpr_pca_seventysix': tpr_pca_seventysix,\n",
    "    'tpr_1em5_pca_seventysix': tpr_1em5_pca_seventysix,\n",
    "    'auc_pca_seventysix': auc_pca_seventysix\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "pca_roc_file = \"pca_roc_variables.pkl\"\n",
    "\n",
    "# Save the variables using pickle\n",
    "with open(pca_roc_file, 'wb') as file:\n",
    "    pickle.dump(pca_roc_variables, file)\n",
    "\n",
    "print(f\"PCA ROC variables saved to {pca_roc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ce787-e414-4025-9a3c-19b9cd713a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables for the standard ROC curve\n",
    "roc_variables = {\n",
    "    'fpr_gaussian': fpr_gaussian,\n",
    "    'tpr_gaussian': tpr_gaussian,\n",
    "    'tpr_1em5_gaussian': tpr_1em5_gaussian,\n",
    "    'auc_gaussian': auc_gaussian,\n",
    "    'fpr_pumap_two': fpr_pumap_two,\n",
    "    'tpr_pumap_two': tpr_pumap_two,\n",
    "    'tpr_1em5_pumap_two': tpr_1em5_pumap_two,\n",
    "    'auc_pumap_two': auc_pumap_two,\n",
    "    'fpr_pumap_three': fpr_pumap_three,\n",
    "    'tpr_pumap_three': tpr_pumap_three,\n",
    "    'tpr_1em5_pumap_three': tpr_1em5_pumap_three,\n",
    "    'auc_pumap_three': auc_pumap_three,\n",
    "    'fpr_pumap_four': fpr_pumap_four,\n",
    "    'tpr_pumap_four': tpr_pumap_four,\n",
    "    'tpr_1em5_pumap_four': tpr_1em5_pumap_four,\n",
    "    'auc_pumap_four': auc_pumap_four,\n",
    "    'fpr_pumap_target': fpr_pumap_target,\n",
    "    'tpr_pumap_target': tpr_pumap_target,\n",
    "    'tpr_1em5_pumap_target': tpr_1em5_pumap_target,\n",
    "    'auc_pumap_target': auc_pumap_target,\n",
    "    'k_pumap': k_pumap,\n",
    "    'fpr_pumap_target_two': fpr_pumap_target_two,\n",
    "    'tpr_pumap_target_two': tpr_pumap_target_two,\n",
    "    'tpr_1em5_pumap_target_two': tpr_1em5_pumap_target_two,\n",
    "    'auc_pumap_target_two': auc_pumap_target_two,\n",
    "    'k_prime_pumap': k_prime_pumap,\n",
    "    'fpr_ae_two': fpr_ae_two,\n",
    "    'tpr_ae_two': tpr_ae_two,\n",
    "    'tpr_1em5_ae_two': tpr_1em5_ae_two,\n",
    "    'auc_ae_two': auc_ae_two,\n",
    "    'fpr_ae_three': fpr_ae_three,\n",
    "    'tpr_ae_three': tpr_ae_three,\n",
    "    'tpr_1em5_ae_three': tpr_1em5_ae_three,\n",
    "    'auc_ae_three': auc_ae_three,\n",
    "    'fpr_ae_four': fpr_ae_four,\n",
    "    'tpr_ae_four': tpr_ae_four,\n",
    "    'tpr_1em5_ae_four': tpr_1em5_ae_four,\n",
    "    'auc_ae_four': auc_ae_four,\n",
    "    'fpr_ae_target': fpr_ae_target,\n",
    "    'tpr_ae_target': tpr_ae_target,\n",
    "    'tpr_1em5_ae_target': tpr_1em5_ae_target,\n",
    "    'auc_ae_target': auc_ae_target,\n",
    "    'k_ae': k_ae,\n",
    "    'fpr_ae_target_two': fpr_ae_target_two,\n",
    "    'tpr_ae_target_two': tpr_ae_target_two,\n",
    "    'tpr_1em5_ae_target_two': tpr_1em5_ae_target_two,\n",
    "    'auc_ae_target_two': auc_ae_target_two,\n",
    "    'k_prime_ae': k_prime_ae,\n",
    "    'fpr_vae_two': fpr_vae_two,\n",
    "    'tpr_vae_two': tpr_vae_two,\n",
    "    'tpr_1em5_vae_two': tpr_1em5_vae_two,\n",
    "    'auc_vae_two': auc_vae_two,\n",
    "    'fpr_vae_three': fpr_vae_three,\n",
    "    'tpr_vae_three': tpr_vae_three,\n",
    "    'tpr_1em5_vae_three': tpr_1em5_vae_three,\n",
    "    'auc_vae_three': auc_vae_three,\n",
    "    'fpr_vae_four': fpr_vae_four,\n",
    "    'tpr_vae_four': tpr_vae_four,\n",
    "    'tpr_1em5_vae_four': tpr_1em5_vae_four,\n",
    "    'auc_vae_four': auc_vae_four,\n",
    "    'fpr_vae_target': fpr_vae_target,\n",
    "    'tpr_vae_target': tpr_vae_target,\n",
    "    'tpr_1em5_vae_target': tpr_1em5_vae_target,\n",
    "    'auc_vae_target': auc_vae_target,\n",
    "    'k_vae': k_vae,\n",
    "    'fpr_vae_target_two': fpr_vae_target_two,\n",
    "    'tpr_vae_target_two': tpr_vae_target_two,\n",
    "    'tpr_1em5_vae_target_two': tpr_1em5_vae_target_two,\n",
    "    'auc_vae_target_two': auc_vae_target_two,\n",
    "    'k_prime_vae': k_prime_vae,\n",
    "    'fpr_pca_two': fpr_pca_two,\n",
    "    'tpr_pca_two': tpr_pca_two,\n",
    "    'tpr_1em5_pca_two': tpr_1em5_pca_two,\n",
    "    'auc_pca_two': auc_pca_two,\n",
    "    'fpr_pca_three': fpr_pca_three,\n",
    "    'tpr_pca_three': tpr_pca_three,\n",
    "    'tpr_1em5_pca_three': tpr_1em5_pca_three,\n",
    "    'auc_pca_three': auc_pca_three,\n",
    "    'fpr_pca_four': fpr_pca_four,\n",
    "    'tpr_pca_four': tpr_pca_four,\n",
    "    'tpr_1em5_pca_four': tpr_1em5_pca_four,\n",
    "    'auc_pca_four': auc_pca_four,\n",
    "    'fpr_pca_target': fpr_pca_target,\n",
    "    'tpr_pca_target': tpr_pca_target,\n",
    "    'tpr_1em5_pca_target': tpr_1em5_pca_target,\n",
    "    'auc_pca_target': auc_pca_target,\n",
    "    'k_pca': k_pca,\n",
    "    'fpr_pca_target_two': fpr_pca_target_two,\n",
    "    'tpr_pca_target_two': tpr_pca_target_two,\n",
    "    'tpr_1em5_pca_target_two': tpr_1em5_pca_target_two,\n",
    "    'auc_pca_target_two': auc_pca_target_two,\n",
    "    'k_prime_pca': k_prime_pca,\n",
    "}\n",
    "\n",
    "# Save variables to a file\n",
    "with open(\"roc_variables.pkl\", \"wb\") as file:\n",
    "    pickle.dump(roc_variables, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fea29-914c-4c6e-9b74-acf3f589da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the requirements.txt\n",
    "try:\n",
    "   with open(\"requirements.txt\", \"w\") as f:\n",
    "       subprocess.run([\"pip\", \"freeze\"], stdout=f, check=True)\n",
    "   print(\"requirements.txt saved successfully!\")\n",
    "except Exception as e:\n",
    "   print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
